{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import pickle\n",
    "import os\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import re\n",
    "import logging\n",
    "import spacy\n",
    "\n",
    "from spacy.lang.en import English\n",
    "\n",
    "import mlflow\n",
    "from mlflow import log_metric, log_param, log_params, log_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='POSTransformer.log',level=logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:18: DeprecationWarning: invalid escape sequence \\w\n",
      "<>:18: DeprecationWarning: invalid escape sequence \\w\n",
      "<>:18: DeprecationWarning: invalid escape sequence \\w\n",
      "<ipython-input-3-7ab039edd683>:18: DeprecationWarning: invalid escape sequence \\w\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ndatasets = os.listdir(\".data/wikitext-2/wikitext-2/\")\\n\\nif \"wiki.train.tokens\" in datasets:\\n    print(\"Removing useless symbols from datasets...\")\\n    pattern = r\"[^\\\\w\\'\\\\.,;:\\\\!\\\\?]\"\\n  #  pattern = r\"[^\\\\w\\']\"\\n    for x in datasets:\\n        with open(f\".data/wikitext-2/wikitext-2/{x}\", \"r\") as _f:\\n            _f = _f.read()\\n\\n        _f = re.sub(pattern, \\' \\', _f)\\n\\n        with open(f\".data/wikitext-2/wikitext-2/{x}\", \"w\") as _w:\\n            _w = _w.write(_f)\\n    print(\"Cleaning finished\")\\n_f = 0\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "datasets = os.listdir(\".data/wikitext-2/wikitext-2/\")\n",
    "\n",
    "if \"wiki.train.tokens\" in datasets:\n",
    "    print(\"Removing useless symbols from datasets...\")\n",
    "    pattern = r\"[^\\w'\\.,;:\\!\\?]\"\n",
    "  #  pattern = r\"[^\\w']\"\n",
    "    for x in datasets:\n",
    "        with open(f\".data/wikitext-2/wikitext-2/{x}\", \"r\") as _f:\n",
    "            _f = _f.read()\n",
    "\n",
    "        _f = re.sub(pattern, ' ', _f)\n",
    "\n",
    "        with open(f\".data/wikitext-2/wikitext-2/{x}\", \"w\") as _w:\n",
    "            _w = _w.write(_f)\n",
    "    print(\"Cleaning finished\")\n",
    "_f = 0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"lr\":1.8,\"epochs\":50,\"embed_dim\":240,\"heads\":8,\"layers\":2,\"seq_len\":32,\"batch_size\":64, \"name\":\"POS2\"}\n",
    "\n",
    "mlflow.set_tracking_uri('http://beefyserv.local:8000/')\n",
    "mlflow.set_experiment(params[\"name\"]+\"-layers\"+str(params[\"layers\"])+\"-heads\"+str(params[\"heads\"]))\n",
    "log_params(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "        r\"\"\"Generate a square mask for the sequence. The masked positions are filled with float('-inf').\n",
    "            Unmasked positions are filled with float(0.0).\n",
    "        \"\"\"\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        mask = mask.to(\"cuda\")\n",
    "        return mask\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        x = self.dropout(x)\n",
    "        x = x.to(\"cuda\")\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, nhead=2, num_encoder_layers=1, ntokens=5000, output=50):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        \n",
    "        self.output = output\n",
    "        self.num_encoder_layers = num_encoder_layers\n",
    "        self.nhead = nhead\n",
    "        self.d_model = d_model\n",
    "        self.ntokens = ntokens\n",
    "        self.emb = nn.Embedding(self.ntokens, self.d_model)\n",
    "        self.posenc = PositionalEncoding(d_model, 0.5)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward=1024)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layers, num_encoder_layers)\n",
    "        self.linear = nn.Linear(self.d_model, self.output)\n",
    "        self.trans_activation = None\n",
    "        \n",
    "    def save_activations(self, epoch=0, batch=0):\n",
    "        \"\"\"\n",
    "        epoch: The running epoch, this information will be added to the files' names.\n",
    "        batch: The running batch, this information will be added to the files' names\n",
    "        \n",
    "        \"\"\"\n",
    "        try:\n",
    "            \n",
    "            for x in range(len(self.transformer.layers)):\n",
    "                # save the activations of each transformer encoder layer.\n",
    "                with open(f\"/PATH/{params['name']}-attention-{x}-{epoch}-{batch}.p\", \"wb\") as _f:\n",
    "                    pickle.dump(self.transformer.layers[x].attn_activation.cpu().detach().numpy(), _f)\n",
    "                           \n",
    "        except:\n",
    "            logging.warning(f\"Model: {params['name']} Failed to save activations for batch {batch} in epoch {epoch}! No More space left on disk!\")\n",
    "        return 0\n",
    "        \n",
    "    \n",
    "    def forward(self, x, tgt, epoch=0, batch=0, flag=\"training\"):\n",
    "        x = self.emb(x) #* math.sqrt(self.d_model)\n",
    "        tgt = self.emb(tgt)\n",
    "        x = self.posenc(x)\n",
    "        x = self.transformer(x, generate_square_subsequent_mask(x.shape[0]))\n",
    "        self.trans_activation = x\n",
    "        if not self.training and flag == \"test\":\n",
    "            self.save_activations(epoch=epoch, batch=batch)\n",
    "        return self.linear(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "TEXT = torchtext.data.Field(tokenize = \"spacy\", tokenizer_language=\"en\", \n",
    "                            init_token=None, \n",
    "                            eos_token=None, \n",
    "                            stop_words = [\"=\", \"==\", \"@\", \"@@\", \"<\", \">\", \"@-@\", \"@,@\",\"@.@\",\"@_@\", \"<eos>\", \"<sos>\", \"<pad>\"], \n",
    "                            lower=True)\n",
    "\n",
    "train_txt, val_txt, test_txt = torchtext.datasets.WikiText2.splits(TEXT)\n",
    "TEXT.build_vocab(train_txt)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def batchify(data, bsz):\n",
    "    data = TEXT.numericalize([data.examples[0].text])\n",
    "    # Divide the dataset into bsz parts.\n",
    "    nbatch = data.size(0) // bsz\n",
    "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
    "    data = data.narrow(0, 0, nbatch * bsz)\n",
    "    # Evenly divide the data across the bsz batches.\n",
    "    data = data.view(bsz, -1).t().contiguous()\n",
    "    return data\n",
    "\n",
    "batch_size = params[\"batch_size\"]\n",
    "eval_batch_size = params[\"batch_size\"]\n",
    "train_data = batchify(train_txt, batch_size)\n",
    "val_data = batchify(val_txt, eval_batch_size)\n",
    "test_data = batchify(test_txt, eval_batch_size)\n",
    "\n",
    "log_params({'val_data':val_data.shape, \n",
    "            'train_data.shape':train_data.shape, \n",
    "            'test_data.shape':test_data.shape, \n",
    "            'batch_size':batch_size, 'eval_batch_size':eval_batch_size})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntags = [0]*len(train_txt.examples[0].text)\\n\\nfrom tqdm import tqdm\\n\\nfor x in tqdm(range(len(train_txt.examples[0].text))):\\n    tags[x] = nlp(train_txt.examples[0].text[x])\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "tags = [0]*len(train_txt.examples[0].text)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "for x in tqdm(range(len(train_txt.examples[0].text))):\n",
    "    tags[x] = nlp(train_txt.examples[0].text[x])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfinaltags = [0]*len(train_txt.examples[0].text)\\nprint(len(tags), len(finaltags))\\n\\nfor x in tqdm(range(len(tags))):\\n    for y in tags[x]:\\n        finaltags[x] = y.tag_\\n\\nprint(finaltags[:50])\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "finaltags = [0]*len(train_txt.examples[0].text)\n",
    "print(len(tags), len(finaltags))\n",
    "\n",
    "for x in tqdm(range(len(tags))):\n",
    "    for y in tags[x]:\n",
    "        finaltags[x] = y.tag_\n",
    "\n",
    "print(finaltags[:50])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nprint(len(finaltags))\\nimport pickle\\nwith open('wikitext.traintags.pickle', 'wb') as handle:\\n    pickle.dump(finaltags, handle, protocol=pickle.HIGHEST_PROTOCOL)\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "print(len(finaltags))\n",
    "import pickle\n",
    "with open('wikitext.traintags.pickle', 'wb') as handle:\n",
    "    pickle.dump(finaltags, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"wikitext.traintags.pickle\", \"rb\") as h:\n",
    "    traintags = pickle.load(h)\n",
    "    \n",
    "with open(\"wikitext.validtags.pickle\", \"rb\") as h:\n",
    "    valtags = pickle.load(h)\n",
    "    \n",
    "with open(\"wikitext.testtags.pickle\", \"rb\") as h:\n",
    "    testtags = pickle.load(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "itotags = {}\n",
    "tagstoi = {}\n",
    "for x in nlp.get_pipe(\"tagger\").labels:\n",
    "    itotags[counter] = x\n",
    "    tagstoi[x] = counter\n",
    "    counter += 1\n",
    "ntags = len(tagstoi.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2056362]) torch.Size([214626])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32130, 64])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintags = torch.Tensor([tagstoi[x] for x in traintags])\n",
    "valtags = torch.Tensor([tagstoi[x] for x in valtags])\n",
    "testtags = torch.Tensor([tagstoi[x] for x in testtags])\n",
    "\n",
    "print(traintags.shape, valtags.shape)\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt = params[\"seq_len\"]\n",
    "\n",
    "def totags(vec):\n",
    "    tagvec = [nlp(TEXT.vocab.itos[x.detach().data]) for x in vec]\n",
    "    tagvec = [y.tag_ for x in tagvec for y in x]\n",
    "    tagvec = [tagstoi[x] for x in tagvec]\n",
    "    assert len(tagvec) == len(vec)\n",
    "    return tagvec\n",
    "\n",
    "def get_tags_batch(source, i, flag=\"other\"):\n",
    "    seq_len = min(bptt, len(source) - 1 - i)\n",
    "    data = source[i:i+seq_len]\n",
    "    if model.training or flag == \"train\":\n",
    "        target = trainingtags[i:i+seq_len].view(-1).long()\n",
    "    elif flag == \"test\":\n",
    "        target = testtags[i:i+seq_len].view(-1).long()\n",
    "    else:\n",
    "        target = validationtags[i:i+seq_len].view(-1).long()\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify_tags(data, bsz):\n",
    "    # Divide the dataset into bsz parts.\n",
    "    nbatch = data.size(0) // bsz\n",
    "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
    "    data = data.narrow(0, 0, nbatch * bsz)\n",
    "    # Evenly divide the data across the bsz batches.\n",
    "    data = data.view(bsz, -1).t().contiguous()\n",
    "    return data\n",
    "\n",
    "trainingtags = batchify_tags(traintags, params[\"batch_size\"])\n",
    "validationtags = batchify_tags(valtags, params[\"batch_size\"])\n",
    "testtags = batchify_tags(testtags, params[\"batch_size\"])\n",
    "log_params({\"training-tags\":trainingtags.shape, \n",
    "            \"validation-tags\":validationtags.shape, \n",
    "            \"test-tags\":testtags.shape})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32130, 64]) torch.Size([32130, 64])\n",
      "torch.Size([3353, 64]) torch.Size([3353, 64])\n",
      "torch.Size([3785, 64]) torch.Size([3785, 64])\n",
      "32130\n"
     ]
    }
   ],
   "source": [
    "ntokens = len(TEXT.vocab.stoi)\n",
    "print(trainingtags.shape, train_data.shape)\n",
    "print(validationtags.shape, val_data.shape)\n",
    "print(testtags.shape, test_data.shape)\n",
    "\n",
    "\n",
    "assert trainingtags.shape == train_data.shape\n",
    "assert validationtags.shape == val_data.shape\n",
    "assert testtags.shape == test_data.shape\n",
    "\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (emb): Embedding(73024, 240)\n",
       "  (posenc): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (transformer): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=240, out_features=240, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=240, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=1024, out_features=240, bias=True)\n",
       "        (norm1): LayerNorm((240,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((240,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=240, out_features=240, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=240, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=1024, out_features=240, bias=True)\n",
       "        (norm1): LayerNorm((240,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((240,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=240, out_features=50, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TransformerModel(d_model=params[\"embed_dim\"], nhead=params[\"heads\"], num_encoder_layers=params[\"layers\"], ntokens=ntokens, output=ntags)\n",
    "model = model.to(\"cuda\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = params[\"lr\"]\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 2.0, gamma=0.65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    cur_loss = 0.\n",
    "    start_time = time.time()\n",
    "    ntokens = len(TEXT.vocab.stoi)\n",
    "    for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n",
    "        data, targets = get_tags_batch(train_data, i)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.to(device), data.to(device), batch=batch, epoch=epoch)\n",
    "        loss = criterion(output.view(-1, ntags), targets.to(device))\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        acc = targets.to(device).eq(torch.argmax(output.view(-1, ntags), dim=1)).sum().detach().cpu().numpy()\n",
    "        acc = acc / targets.shape[0]\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "        log_interval = params[\"batch_size\"]\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            cur_loss = total_loss / log_interval\n",
    "            log_metrics({\"train_loss\":cur_loss, \"train_accuracy\":acc})\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches | '\n",
    "                  'lr {:02.4f} | ms/batch {:5.2f} | '\n",
    "                  'loss {:5.2f} | acc {:8.2f}'.format(\n",
    "                    epoch, batch, len(train_data) // bptt, scheduler.get_lr()[0],\n",
    "                    elapsed * 1000 / log_interval,\n",
    "                    cur_loss, acc))\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "    \n",
    "\n",
    "def evaluate(eval_model, data_source, flag):\n",
    "    eval_model.eval() \n",
    "    total_loss = 0.\n",
    "    ntokens = len(TEXT.vocab.stoi)\n",
    "    acc = 0\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, data_source.size(0) - 1, bptt):\n",
    "            data, targets = get_tags_batch(data_source, i, flag)\n",
    "            output = eval_model(data.to(device), data.to(device),batch=i, epoch=epoch, flag=flag)\n",
    "            acc = targets.to(device).eq(torch.argmax(output.view(-1, ntags), dim=1)).sum().detach().cpu().numpy()\n",
    "            acc = acc / targets.shape[0]\n",
    "            output_flat = output.view(-1, ntags)\n",
    "            loss = criterion(output_flat, targets.to(device))\n",
    "            total_loss += params[\"batch_size\"] * loss.item()\n",
    "    return total_loss / (len(data_source) - 1), acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING:::::::.........\n",
      "| epoch   1 |    64/ 1004 batches | lr 1.8000 | ms/batch 89.38 | loss  2.12 | acc     0.54\n",
      "| epoch   1 |   128/ 1004 batches | lr 1.8000 | ms/batch 85.71 | loss  1.46 | acc     0.61\n",
      "| epoch   1 |   192/ 1004 batches | lr 1.8000 | ms/batch 101.73 | loss  1.24 | acc     0.64\n",
      "| epoch   1 |   256/ 1004 batches | lr 1.8000 | ms/batch 85.44 | loss  1.12 | acc     0.63\n",
      "| epoch   1 |   320/ 1004 batches | lr 1.8000 | ms/batch 84.81 | loss  1.03 | acc     0.64\n",
      "| epoch   1 |   384/ 1004 batches | lr 1.8000 | ms/batch 82.99 | loss  0.95 | acc     0.71\n",
      "| epoch   1 |   448/ 1004 batches | lr 1.8000 | ms/batch 83.77 | loss  0.88 | acc     0.72\n",
      "| epoch   1 |   512/ 1004 batches | lr 1.8000 | ms/batch 83.50 | loss  0.82 | acc     0.74\n",
      "| epoch   1 |   576/ 1004 batches | lr 1.8000 | ms/batch 83.89 | loss  0.77 | acc     0.72\n",
      "| epoch   1 |   640/ 1004 batches | lr 1.8000 | ms/batch 84.54 | loss  0.73 | acc     0.75\n",
      "| epoch   1 |   704/ 1004 batches | lr 1.8000 | ms/batch 88.98 | loss  0.70 | acc     0.78\n",
      "| epoch   1 |   768/ 1004 batches | lr 1.8000 | ms/batch 85.05 | loss  0.66 | acc     0.79\n",
      "| epoch   1 |   832/ 1004 batches | lr 1.8000 | ms/batch 84.93 | loss  0.64 | acc     0.79\n",
      "| epoch   1 |   896/ 1004 batches | lr 1.8000 | ms/batch 85.71 | loss  0.61 | acc     0.80\n",
      "| epoch   1 |   960/ 1004 batches | lr 1.8000 | ms/batch 85.07 | loss  0.61 | acc     0.81\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 109.35s | valid loss  0.71 | valid acc     0.89\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   2 |    64/ 1004 batches | lr 1.8000 | ms/batch 86.21 | loss  0.58 | acc     0.83\n",
      "| epoch   2 |   128/ 1004 batches | lr 1.8000 | ms/batch 84.69 | loss  0.55 | acc     0.81\n",
      "| epoch   2 |   192/ 1004 batches | lr 1.8000 | ms/batch 84.87 | loss  0.53 | acc     0.84\n",
      "| epoch   2 |   256/ 1004 batches | lr 1.8000 | ms/batch 86.29 | loss  0.53 | acc     0.82\n",
      "| epoch   2 |   320/ 1004 batches | lr 1.8000 | ms/batch 84.29 | loss  0.53 | acc     0.84\n",
      "| epoch   2 |   384/ 1004 batches | lr 1.8000 | ms/batch 84.15 | loss  0.51 | acc     0.84\n",
      "| epoch   2 |   448/ 1004 batches | lr 1.8000 | ms/batch 84.41 | loss  0.49 | acc     0.84\n",
      "| epoch   2 |   512/ 1004 batches | lr 1.8000 | ms/batch 83.91 | loss  0.49 | acc     0.86\n",
      "| epoch   2 |   576/ 1004 batches | lr 1.8000 | ms/batch 83.62 | loss  0.48 | acc     0.84\n",
      "| epoch   2 |   640/ 1004 batches | lr 1.8000 | ms/batch 83.64 | loss  0.48 | acc     0.85\n",
      "| epoch   2 |   704/ 1004 batches | lr 1.8000 | ms/batch 83.64 | loss  0.47 | acc     0.86\n",
      "| epoch   2 |   768/ 1004 batches | lr 1.8000 | ms/batch 83.20 | loss  0.46 | acc     0.86\n",
      "| epoch   2 |   832/ 1004 batches | lr 1.8000 | ms/batch 87.06 | loss  0.46 | acc     0.86\n",
      "| epoch   2 |   896/ 1004 batches | lr 1.8000 | ms/batch 82.98 | loss  0.45 | acc     0.86\n",
      "| epoch   2 |   960/ 1004 batches | lr 1.8000 | ms/batch 83.50 | loss  0.46 | acc     0.86\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 107.42s | valid loss  0.52 | valid acc     0.92\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   3 |    64/ 1004 batches | lr 1.1700 | ms/batch 82.29 | loss  0.43 | acc     0.87\n",
      "| epoch   3 |   128/ 1004 batches | lr 1.1700 | ms/batch 80.90 | loss  0.42 | acc     0.85\n",
      "| epoch   3 |   192/ 1004 batches | lr 1.1700 | ms/batch 80.90 | loss  0.41 | acc     0.88\n",
      "| epoch   3 |   256/ 1004 batches | lr 1.1700 | ms/batch 81.17 | loss  0.41 | acc     0.89\n",
      "| epoch   3 |   320/ 1004 batches | lr 1.1700 | ms/batch 80.90 | loss  0.42 | acc     0.87\n",
      "| epoch   3 |   384/ 1004 batches | lr 1.1700 | ms/batch 80.90 | loss  0.40 | acc     0.87\n",
      "| epoch   3 |   448/ 1004 batches | lr 1.1700 | ms/batch 81.02 | loss  0.39 | acc     0.88\n",
      "| epoch   3 |   512/ 1004 batches | lr 1.1700 | ms/batch 81.16 | loss  0.39 | acc     0.87\n",
      "| epoch   3 |   576/ 1004 batches | lr 1.1700 | ms/batch 80.90 | loss  0.39 | acc     0.88\n",
      "| epoch   3 |   640/ 1004 batches | lr 1.1700 | ms/batch 81.43 | loss  0.39 | acc     0.88\n",
      "| epoch   3 |   704/ 1004 batches | lr 1.1700 | ms/batch 80.77 | loss  0.38 | acc     0.89\n",
      "| epoch   3 |   768/ 1004 batches | lr 1.1700 | ms/batch 81.30 | loss  0.38 | acc     0.88\n",
      "| epoch   3 |   832/ 1004 batches | lr 1.1700 | ms/batch 81.28 | loss  0.38 | acc     0.87\n",
      "| epoch   3 |   896/ 1004 batches | lr 1.1700 | ms/batch 81.04 | loss  0.38 | acc     0.88\n",
      "| epoch   3 |   960/ 1004 batches | lr 1.1700 | ms/batch 84.41 | loss  0.39 | acc     0.87\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 104.53s | valid loss  0.41 | valid acc     0.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   4 |    64/ 1004 batches | lr 1.1700 | ms/batch 83.33 | loss  0.38 | acc     0.88\n",
      "| epoch   4 |   128/ 1004 batches | lr 1.1700 | ms/batch 82.21 | loss  0.37 | acc     0.86\n",
      "| epoch   4 |   192/ 1004 batches | lr 1.1700 | ms/batch 82.07 | loss  0.37 | acc     0.89\n",
      "| epoch   4 |   256/ 1004 batches | lr 1.1700 | ms/batch 82.72 | loss  0.37 | acc     0.89\n",
      "| epoch   4 |   320/ 1004 batches | lr 1.1700 | ms/batch 81.94 | loss  0.38 | acc     0.88\n",
      "| epoch   4 |   384/ 1004 batches | lr 1.1700 | ms/batch 82.07 | loss  0.37 | acc     0.90\n",
      "| epoch   4 |   448/ 1004 batches | lr 1.1700 | ms/batch 82.22 | loss  0.36 | acc     0.89\n",
      "| epoch   4 |   512/ 1004 batches | lr 1.1700 | ms/batch 82.44 | loss  0.36 | acc     0.90\n",
      "| epoch   4 |   576/ 1004 batches | lr 1.1700 | ms/batch 82.08 | loss  0.36 | acc     0.89\n",
      "| epoch   4 |   640/ 1004 batches | lr 1.1700 | ms/batch 82.32 | loss  0.36 | acc     0.89\n",
      "| epoch   4 |   704/ 1004 batches | lr 1.1700 | ms/batch 82.34 | loss  0.36 | acc     0.90\n",
      "| epoch   4 |   768/ 1004 batches | lr 1.1700 | ms/batch 82.13 | loss  0.35 | acc     0.89\n",
      "| epoch   4 |   832/ 1004 batches | lr 1.1700 | ms/batch 82.01 | loss  0.35 | acc     0.90\n",
      "| epoch   4 |   896/ 1004 batches | lr 1.1700 | ms/batch 82.07 | loss  0.35 | acc     0.89\n",
      "| epoch   4 |   960/ 1004 batches | lr 1.1700 | ms/batch 82.08 | loss  0.36 | acc     0.89\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time: 106.02s | valid loss  0.41 | valid acc     0.93\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   5 |    64/ 1004 batches | lr 0.7605 | ms/batch 81.97 | loss  0.36 | acc     0.90\n",
      "| epoch   5 |   128/ 1004 batches | lr 0.7605 | ms/batch 80.78 | loss  0.34 | acc     0.88\n",
      "| epoch   5 |   192/ 1004 batches | lr 0.7605 | ms/batch 80.76 | loss  0.34 | acc     0.90\n",
      "| epoch   5 |   256/ 1004 batches | lr 0.7605 | ms/batch 81.01 | loss  0.34 | acc     0.90\n",
      "| epoch   5 |   320/ 1004 batches | lr 0.7605 | ms/batch 80.80 | loss  0.35 | acc     0.88\n",
      "| epoch   5 |   384/ 1004 batches | lr 0.7605 | ms/batch 80.89 | loss  0.34 | acc     0.90\n",
      "| epoch   5 |   448/ 1004 batches | lr 0.7605 | ms/batch 80.77 | loss  0.33 | acc     0.89\n",
      "| epoch   5 |   512/ 1004 batches | lr 0.7605 | ms/batch 80.78 | loss  0.33 | acc     0.89\n",
      "| epoch   5 |   576/ 1004 batches | lr 0.7605 | ms/batch 80.64 | loss  0.33 | acc     0.90\n",
      "| epoch   5 |   640/ 1004 batches | lr 0.7605 | ms/batch 80.78 | loss  0.33 | acc     0.90\n",
      "| epoch   5 |   704/ 1004 batches | lr 0.7605 | ms/batch 80.77 | loss  0.33 | acc     0.91\n",
      "| epoch   5 |   768/ 1004 batches | lr 0.7605 | ms/batch 80.77 | loss  0.32 | acc     0.91\n",
      "| epoch   5 |   832/ 1004 batches | lr 0.7605 | ms/batch 80.90 | loss  0.32 | acc     0.91\n",
      "| epoch   5 |   896/ 1004 batches | lr 0.7605 | ms/batch 80.90 | loss  0.32 | acc     0.90\n",
      "| epoch   5 |   960/ 1004 batches | lr 0.7605 | ms/batch 80.79 | loss  0.34 | acc     0.88\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time: 104.55s | valid loss  0.37 | valid acc     0.94\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   6 |    64/ 1004 batches | lr 0.7605 | ms/batch 85.38 | loss  0.33 | acc     0.90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   6 |   128/ 1004 batches | lr 0.7605 | ms/batch 80.97 | loss  0.33 | acc     0.89\n",
      "| epoch   6 |   192/ 1004 batches | lr 0.7605 | ms/batch 80.78 | loss  0.32 | acc     0.90\n",
      "| epoch   6 |   256/ 1004 batches | lr 0.7605 | ms/batch 80.76 | loss  0.32 | acc     0.89\n",
      "| epoch   6 |   320/ 1004 batches | lr 0.7605 | ms/batch 80.65 | loss  0.33 | acc     0.90\n",
      "| epoch   6 |   384/ 1004 batches | lr 0.7605 | ms/batch 80.76 | loss  0.32 | acc     0.90\n",
      "| epoch   6 |   448/ 1004 batches | lr 0.7605 | ms/batch 80.79 | loss  0.32 | acc     0.90\n",
      "| epoch   6 |   512/ 1004 batches | lr 0.7605 | ms/batch 80.76 | loss  0.31 | acc     0.91\n",
      "| epoch   6 |   576/ 1004 batches | lr 0.7605 | ms/batch 80.89 | loss  0.32 | acc     0.91\n",
      "| epoch   6 |   640/ 1004 batches | lr 0.7605 | ms/batch 80.78 | loss  0.31 | acc     0.89\n",
      "| epoch   6 |   704/ 1004 batches | lr 0.7605 | ms/batch 80.90 | loss  0.32 | acc     0.90\n",
      "| epoch   6 |   768/ 1004 batches | lr 0.7605 | ms/batch 80.90 | loss  0.31 | acc     0.90\n",
      "| epoch   6 |   832/ 1004 batches | lr 0.7605 | ms/batch 80.90 | loss  0.31 | acc     0.90\n",
      "| epoch   6 |   896/ 1004 batches | lr 0.7605 | ms/batch 80.91 | loss  0.31 | acc     0.90\n",
      "| epoch   6 |   960/ 1004 batches | lr 0.7605 | ms/batch 80.77 | loss  0.32 | acc     0.90\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time: 105.01s | valid loss  0.34 | valid acc     0.94\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   7 |    64/ 1004 batches | lr 0.4943 | ms/batch 84.70 | loss  0.32 | acc     0.90\n",
      "| epoch   7 |   128/ 1004 batches | lr 0.4943 | ms/batch 83.25 | loss  0.31 | acc     0.89\n",
      "| epoch   7 |   192/ 1004 batches | lr 0.4943 | ms/batch 83.29 | loss  0.31 | acc     0.90\n",
      "| epoch   7 |   256/ 1004 batches | lr 0.4943 | ms/batch 86.98 | loss  0.31 | acc     0.91\n",
      "| epoch   7 |   320/ 1004 batches | lr 0.4943 | ms/batch 83.31 | loss  0.32 | acc     0.91\n",
      "| epoch   7 |   384/ 1004 batches | lr 0.4943 | ms/batch 83.04 | loss  0.30 | acc     0.91\n",
      "| epoch   7 |   448/ 1004 batches | lr 0.4943 | ms/batch 82.98 | loss  0.30 | acc     0.91\n",
      "| epoch   7 |   512/ 1004 batches | lr 0.4943 | ms/batch 83.15 | loss  0.30 | acc     0.92\n",
      "| epoch   7 |   576/ 1004 batches | lr 0.4943 | ms/batch 83.23 | loss  0.30 | acc     0.91\n",
      "| epoch   7 |   640/ 1004 batches | lr 0.4943 | ms/batch 83.24 | loss  0.30 | acc     0.90\n",
      "| epoch   7 |   704/ 1004 batches | lr 0.4943 | ms/batch 83.23 | loss  0.30 | acc     0.92\n",
      "| epoch   7 |   768/ 1004 batches | lr 0.4943 | ms/batch 83.12 | loss  0.30 | acc     0.90\n",
      "| epoch   7 |   832/ 1004 batches | lr 0.4943 | ms/batch 82.20 | loss  0.30 | acc     0.91\n",
      "| epoch   7 |   896/ 1004 batches | lr 0.4943 | ms/batch 82.19 | loss  0.29 | acc     0.91\n",
      "| epoch   7 |   960/ 1004 batches | lr 0.4943 | ms/batch 82.08 | loss  0.31 | acc     0.90\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   7 | time: 106.93s | valid loss  0.34 | valid acc     0.94\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   8 |    64/ 1004 batches | lr 0.4943 | ms/batch 82.87 | loss  0.31 | acc     0.91\n",
      "| epoch   8 |   128/ 1004 batches | lr 0.4943 | ms/batch 81.55 | loss  0.30 | acc     0.89\n",
      "| epoch   8 |   192/ 1004 batches | lr 0.4943 | ms/batch 81.96 | loss  0.30 | acc     0.91\n",
      "| epoch   8 |   256/ 1004 batches | lr 0.4943 | ms/batch 81.67 | loss  0.30 | acc     0.92\n",
      "| epoch   8 |   320/ 1004 batches | lr 0.4943 | ms/batch 81.68 | loss  0.31 | acc     0.91\n",
      "| epoch   8 |   384/ 1004 batches | lr 0.4943 | ms/batch 84.43 | loss  0.30 | acc     0.92\n",
      "| epoch   8 |   448/ 1004 batches | lr 0.4943 | ms/batch 81.92 | loss  0.29 | acc     0.91\n",
      "| epoch   8 |   512/ 1004 batches | lr 0.4943 | ms/batch 81.68 | loss  0.29 | acc     0.92\n",
      "| epoch   8 |   576/ 1004 batches | lr 0.4943 | ms/batch 81.82 | loss  0.29 | acc     0.92\n",
      "| epoch   8 |   640/ 1004 batches | lr 0.4943 | ms/batch 81.55 | loss  0.29 | acc     0.91\n",
      "| epoch   8 |   704/ 1004 batches | lr 0.4943 | ms/batch 81.67 | loss  0.29 | acc     0.92\n",
      "| epoch   8 |   768/ 1004 batches | lr 0.4943 | ms/batch 81.56 | loss  0.29 | acc     0.91\n",
      "| epoch   8 |   832/ 1004 batches | lr 0.4943 | ms/batch 81.69 | loss  0.29 | acc     0.91\n",
      "| epoch   8 |   896/ 1004 batches | lr 0.4943 | ms/batch 81.80 | loss  0.29 | acc     0.91\n",
      "| epoch   8 |   960/ 1004 batches | lr 0.4943 | ms/batch 81.56 | loss  0.30 | acc     0.90\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   8 | time: 105.95s | valid loss  0.34 | valid acc     0.94\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   9 |    64/ 1004 batches | lr 0.3213 | ms/batch 83.43 | loss  0.30 | acc     0.92\n",
      "| epoch   9 |   128/ 1004 batches | lr 0.3213 | ms/batch 81.95 | loss  0.29 | acc     0.90\n",
      "| epoch   9 |   192/ 1004 batches | lr 0.3213 | ms/batch 81.93 | loss  0.29 | acc     0.92\n",
      "| epoch   9 |   256/ 1004 batches | lr 0.3213 | ms/batch 82.07 | loss  0.29 | acc     0.91\n",
      "| epoch   9 |   320/ 1004 batches | lr 0.3213 | ms/batch 82.21 | loss  0.30 | acc     0.91\n",
      "| epoch   9 |   384/ 1004 batches | lr 0.3213 | ms/batch 81.68 | loss  0.29 | acc     0.92\n",
      "| epoch   9 |   448/ 1004 batches | lr 0.3213 | ms/batch 81.69 | loss  0.29 | acc     0.91\n",
      "| epoch   9 |   512/ 1004 batches | lr 0.3213 | ms/batch 81.93 | loss  0.28 | acc     0.92\n",
      "| epoch   9 |   576/ 1004 batches | lr 0.3213 | ms/batch 86.24 | loss  0.28 | acc     0.92\n",
      "| epoch   9 |   640/ 1004 batches | lr 0.3213 | ms/batch 81.28 | loss  0.28 | acc     0.91\n",
      "| epoch   9 |   704/ 1004 batches | lr 0.3213 | ms/batch 81.16 | loss  0.29 | acc     0.92\n",
      "| epoch   9 |   768/ 1004 batches | lr 0.3213 | ms/batch 81.17 | loss  0.28 | acc     0.91\n",
      "| epoch   9 |   832/ 1004 batches | lr 0.3213 | ms/batch 81.56 | loss  0.28 | acc     0.91\n",
      "| epoch   9 |   896/ 1004 batches | lr 0.3213 | ms/batch 81.29 | loss  0.28 | acc     0.92\n",
      "| epoch   9 |   960/ 1004 batches | lr 0.3213 | ms/batch 81.17 | loss  0.29 | acc     0.91\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   9 | time: 105.93s | valid loss  0.31 | valid acc     0.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  10 |    64/ 1004 batches | lr 0.3213 | ms/batch 84.79 | loss  0.29 | acc     0.91\n",
      "| epoch  10 |   128/ 1004 batches | lr 0.3213 | ms/batch 83.77 | loss  0.29 | acc     0.91\n",
      "| epoch  10 |   192/ 1004 batches | lr 0.3213 | ms/batch 83.26 | loss  0.28 | acc     0.91\n",
      "| epoch  10 |   256/ 1004 batches | lr 0.3213 | ms/batch 83.35 | loss  0.28 | acc     0.92\n",
      "| epoch  10 |   320/ 1004 batches | lr 0.3213 | ms/batch 83.36 | loss  0.29 | acc     0.91\n",
      "| epoch  10 |   384/ 1004 batches | lr 0.3213 | ms/batch 83.78 | loss  0.28 | acc     0.92\n",
      "| epoch  10 |   448/ 1004 batches | lr 0.3213 | ms/batch 83.23 | loss  0.28 | acc     0.92\n",
      "| epoch  10 |   512/ 1004 batches | lr 0.3213 | ms/batch 83.24 | loss  0.27 | acc     0.92\n",
      "| epoch  10 |   576/ 1004 batches | lr 0.3213 | ms/batch 83.38 | loss  0.28 | acc     0.92\n",
      "| epoch  10 |   640/ 1004 batches | lr 0.3213 | ms/batch 83.25 | loss  0.28 | acc     0.90\n",
      "| epoch  10 |   704/ 1004 batches | lr 0.3213 | ms/batch 86.89 | loss  0.28 | acc     0.93\n",
      "| epoch  10 |   768/ 1004 batches | lr 0.3213 | ms/batch 83.10 | loss  0.27 | acc     0.92\n",
      "| epoch  10 |   832/ 1004 batches | lr 0.3213 | ms/batch 83.11 | loss  0.28 | acc     0.92\n",
      "| epoch  10 |   896/ 1004 batches | lr 0.3213 | ms/batch 83.11 | loss  0.27 | acc     0.92\n",
      "| epoch  10 |   960/ 1004 batches | lr 0.3213 | ms/batch 83.12 | loss  0.29 | acc     0.91\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  10 | time: 107.67s | valid loss  0.32 | valid acc     0.94\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  11 |    64/ 1004 batches | lr 0.2089 | ms/batch 83.36 | loss  0.29 | acc     0.91\n",
      "| epoch  11 |   128/ 1004 batches | lr 0.2089 | ms/batch 82.32 | loss  0.28 | acc     0.90\n",
      "| epoch  11 |   192/ 1004 batches | lr 0.2089 | ms/batch 82.33 | loss  0.28 | acc     0.91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  11 |   256/ 1004 batches | lr 0.2089 | ms/batch 82.20 | loss  0.28 | acc     0.93\n",
      "| epoch  11 |   320/ 1004 batches | lr 0.2089 | ms/batch 82.21 | loss  0.29 | acc     0.91\n",
      "| epoch  11 |   384/ 1004 batches | lr 0.2089 | ms/batch 82.20 | loss  0.28 | acc     0.91\n",
      "| epoch  11 |   448/ 1004 batches | lr 0.2089 | ms/batch 82.33 | loss  0.27 | acc     0.91\n",
      "| epoch  11 |   512/ 1004 batches | lr 0.2089 | ms/batch 82.46 | loss  0.27 | acc     0.93\n",
      "| epoch  11 |   576/ 1004 batches | lr 0.2089 | ms/batch 82.07 | loss  0.27 | acc     0.92\n",
      "| epoch  11 |   640/ 1004 batches | lr 0.2089 | ms/batch 82.21 | loss  0.27 | acc     0.92\n",
      "| epoch  11 |   704/ 1004 batches | lr 0.2089 | ms/batch 82.21 | loss  0.28 | acc     0.92\n",
      "| epoch  11 |   768/ 1004 batches | lr 0.2089 | ms/batch 82.08 | loss  0.27 | acc     0.92\n",
      "| epoch  11 |   832/ 1004 batches | lr 0.2089 | ms/batch 85.85 | loss  0.27 | acc     0.92\n",
      "| epoch  11 |   896/ 1004 batches | lr 0.2089 | ms/batch 82.06 | loss  0.27 | acc     0.91\n",
      "| epoch  11 |   960/ 1004 batches | lr 0.2089 | ms/batch 81.69 | loss  0.28 | acc     0.91\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  11 | time: 106.28s | valid loss  0.31 | valid acc     0.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  12 |    64/ 1004 batches | lr 0.2089 | ms/batch 84.52 | loss  0.28 | acc     0.92\n",
      "| epoch  12 |   128/ 1004 batches | lr 0.2089 | ms/batch 83.23 | loss  0.28 | acc     0.91\n",
      "| epoch  12 |   192/ 1004 batches | lr 0.2089 | ms/batch 83.37 | loss  0.27 | acc     0.92\n",
      "| epoch  12 |   256/ 1004 batches | lr 0.2089 | ms/batch 83.38 | loss  0.28 | acc     0.92\n",
      "| epoch  12 |   320/ 1004 batches | lr 0.2089 | ms/batch 83.50 | loss  0.28 | acc     0.91\n",
      "| epoch  12 |   384/ 1004 batches | lr 0.2089 | ms/batch 83.57 | loss  0.28 | acc     0.92\n",
      "| epoch  12 |   448/ 1004 batches | lr 0.2089 | ms/batch 83.86 | loss  0.27 | acc     0.92\n",
      "| epoch  12 |   512/ 1004 batches | lr 0.2089 | ms/batch 83.94 | loss  0.27 | acc     0.93\n",
      "| epoch  12 |   576/ 1004 batches | lr 0.2089 | ms/batch 83.80 | loss  0.27 | acc     0.92\n",
      "| epoch  12 |   640/ 1004 batches | lr 0.2089 | ms/batch 83.27 | loss  0.27 | acc     0.91\n",
      "| epoch  12 |   704/ 1004 batches | lr 0.2089 | ms/batch 83.50 | loss  0.27 | acc     0.93\n",
      "| epoch  12 |   768/ 1004 batches | lr 0.2089 | ms/batch 84.93 | loss  0.27 | acc     0.91\n",
      "| epoch  12 |   832/ 1004 batches | lr 0.2089 | ms/batch 86.00 | loss  0.27 | acc     0.92\n",
      "| epoch  12 |   896/ 1004 batches | lr 0.2089 | ms/batch 83.25 | loss  0.27 | acc     0.92\n",
      "| epoch  12 |   960/ 1004 batches | lr 0.2089 | ms/batch 86.85 | loss  0.28 | acc     0.91\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  12 | time: 108.07s | valid loss  0.30 | valid acc     0.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  13 |    64/ 1004 batches | lr 0.1358 | ms/batch 85.83 | loss  0.28 | acc     0.92\n",
      "| epoch  13 |   128/ 1004 batches | lr 0.1358 | ms/batch 83.21 | loss  0.28 | acc     0.91\n",
      "| epoch  13 |   192/ 1004 batches | lr 0.1358 | ms/batch 83.39 | loss  0.27 | acc     0.92\n",
      "| epoch  13 |   256/ 1004 batches | lr 0.1358 | ms/batch 84.17 | loss  0.27 | acc     0.92\n",
      "| epoch  13 |   320/ 1004 batches | lr 0.1358 | ms/batch 83.46 | loss  0.28 | acc     0.92\n",
      "| epoch  13 |   384/ 1004 batches | lr 0.1358 | ms/batch 83.50 | loss  0.27 | acc     0.91\n",
      "| epoch  13 |   448/ 1004 batches | lr 0.1358 | ms/batch 83.87 | loss  0.26 | acc     0.92\n",
      "| epoch  13 |   512/ 1004 batches | lr 0.1358 | ms/batch 83.26 | loss  0.26 | acc     0.93\n",
      "| epoch  13 |   576/ 1004 batches | lr 0.1358 | ms/batch 83.90 | loss  0.27 | acc     0.92\n",
      "| epoch  13 |   640/ 1004 batches | lr 0.1358 | ms/batch 83.88 | loss  0.27 | acc     0.91\n",
      "| epoch  13 |   704/ 1004 batches | lr 0.1358 | ms/batch 83.52 | loss  0.27 | acc     0.92\n",
      "| epoch  13 |   768/ 1004 batches | lr 0.1358 | ms/batch 83.77 | loss  0.27 | acc     0.92\n",
      "| epoch  13 |   832/ 1004 batches | lr 0.1358 | ms/batch 83.37 | loss  0.27 | acc     0.92\n",
      "| epoch  13 |   896/ 1004 batches | lr 0.1358 | ms/batch 83.65 | loss  0.26 | acc     0.92\n",
      "| epoch  13 |   960/ 1004 batches | lr 0.1358 | ms/batch 83.56 | loss  0.28 | acc     0.92\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  13 | time: 109.11s | valid loss  0.30 | valid acc     0.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  14 |    64/ 1004 batches | lr 0.1358 | ms/batch 83.93 | loss  0.28 | acc     0.92\n",
      "| epoch  14 |   128/ 1004 batches | lr 0.1358 | ms/batch 82.23 | loss  0.27 | acc     0.91\n",
      "| epoch  14 |   192/ 1004 batches | lr 0.1358 | ms/batch 82.31 | loss  0.27 | acc     0.92\n",
      "| epoch  14 |   256/ 1004 batches | lr 0.1358 | ms/batch 82.75 | loss  0.27 | acc     0.93\n",
      "| epoch  14 |   320/ 1004 batches | lr 0.1358 | ms/batch 82.31 | loss  0.28 | acc     0.92\n",
      "| epoch  14 |   384/ 1004 batches | lr 0.1358 | ms/batch 82.20 | loss  0.27 | acc     0.92\n",
      "| epoch  14 |   448/ 1004 batches | lr 0.1358 | ms/batch 82.42 | loss  0.26 | acc     0.92\n",
      "| epoch  14 |   512/ 1004 batches | lr 0.1358 | ms/batch 82.54 | loss  0.26 | acc     0.92\n",
      "| epoch  14 |   576/ 1004 batches | lr 0.1358 | ms/batch 82.18 | loss  0.27 | acc     0.91\n",
      "| epoch  14 |   640/ 1004 batches | lr 0.1358 | ms/batch 82.59 | loss  0.27 | acc     0.91\n",
      "| epoch  14 |   704/ 1004 batches | lr 0.1358 | ms/batch 83.23 | loss  0.27 | acc     0.93\n",
      "| epoch  14 |   768/ 1004 batches | lr 0.1358 | ms/batch 82.22 | loss  0.26 | acc     0.92\n",
      "| epoch  14 |   832/ 1004 batches | lr 0.1358 | ms/batch 82.59 | loss  0.26 | acc     0.92\n",
      "| epoch  14 |   896/ 1004 batches | lr 0.1358 | ms/batch 84.48 | loss  0.26 | acc     0.92\n",
      "| epoch  14 |   960/ 1004 batches | lr 0.1358 | ms/batch 83.18 | loss  0.27 | acc     0.92\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  14 | time: 106.73s | valid loss  0.29 | valid acc     0.96\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  15 |    64/ 1004 batches | lr 0.0882 | ms/batch 88.96 | loss  0.28 | acc     0.92\n",
      "| epoch  15 |   128/ 1004 batches | lr 0.0882 | ms/batch 83.37 | loss  0.27 | acc     0.91\n",
      "| epoch  15 |   192/ 1004 batches | lr 0.0882 | ms/batch 83.36 | loss  0.27 | acc     0.91\n",
      "| epoch  15 |   256/ 1004 batches | lr 0.0882 | ms/batch 83.51 | loss  0.27 | acc     0.92\n",
      "| epoch  15 |   320/ 1004 batches | lr 0.0882 | ms/batch 83.24 | loss  0.28 | acc     0.92\n",
      "| epoch  15 |   384/ 1004 batches | lr 0.0882 | ms/batch 83.25 | loss  0.27 | acc     0.92\n",
      "| epoch  15 |   448/ 1004 batches | lr 0.0882 | ms/batch 83.24 | loss  0.26 | acc     0.92\n",
      "| epoch  15 |   512/ 1004 batches | lr 0.0882 | ms/batch 83.11 | loss  0.26 | acc     0.93\n",
      "| epoch  15 |   576/ 1004 batches | lr 0.0882 | ms/batch 83.25 | loss  0.26 | acc     0.92\n",
      "| epoch  15 |   640/ 1004 batches | lr 0.0882 | ms/batch 83.37 | loss  0.26 | acc     0.92\n",
      "| epoch  15 |   704/ 1004 batches | lr 0.0882 | ms/batch 83.23 | loss  0.27 | acc     0.93\n",
      "| epoch  15 |   768/ 1004 batches | lr 0.0882 | ms/batch 83.38 | loss  0.26 | acc     0.92\n",
      "| epoch  15 |   832/ 1004 batches | lr 0.0882 | ms/batch 83.25 | loss  0.26 | acc     0.92\n",
      "| epoch  15 |   896/ 1004 batches | lr 0.0882 | ms/batch 83.24 | loss  0.26 | acc     0.92\n",
      "| epoch  15 |   960/ 1004 batches | lr 0.0882 | ms/batch 83.11 | loss  0.27 | acc     0.91\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  15 | time: 107.79s | valid loss  0.30 | valid acc     0.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  16 |    64/ 1004 batches | lr 0.0882 | ms/batch 82.47 | loss  0.27 | acc     0.93\n",
      "| epoch  16 |   128/ 1004 batches | lr 0.0882 | ms/batch 81.29 | loss  0.27 | acc     0.91\n",
      "| epoch  16 |   192/ 1004 batches | lr 0.0882 | ms/batch 84.68 | loss  0.26 | acc     0.93\n",
      "| epoch  16 |   256/ 1004 batches | lr 0.0882 | ms/batch 81.28 | loss  0.27 | acc     0.92\n",
      "| epoch  16 |   320/ 1004 batches | lr 0.0882 | ms/batch 81.30 | loss  0.28 | acc     0.92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  16 |   384/ 1004 batches | lr 0.0882 | ms/batch 81.04 | loss  0.26 | acc     0.92\n",
      "| epoch  16 |   448/ 1004 batches | lr 0.0882 | ms/batch 81.29 | loss  0.26 | acc     0.91\n",
      "| epoch  16 |   512/ 1004 batches | lr 0.0882 | ms/batch 81.03 | loss  0.26 | acc     0.92\n",
      "| epoch  16 |   576/ 1004 batches | lr 0.0882 | ms/batch 81.04 | loss  0.26 | acc     0.93\n",
      "| epoch  16 |   640/ 1004 batches | lr 0.0882 | ms/batch 81.42 | loss  0.26 | acc     0.92\n",
      "| epoch  16 |   704/ 1004 batches | lr 0.0882 | ms/batch 81.81 | loss  0.26 | acc     0.93\n",
      "| epoch  16 |   768/ 1004 batches | lr 0.0882 | ms/batch 81.68 | loss  0.26 | acc     0.92\n",
      "| epoch  16 |   832/ 1004 batches | lr 0.0882 | ms/batch 81.81 | loss  0.26 | acc     0.93\n",
      "| epoch  16 |   896/ 1004 batches | lr 0.0882 | ms/batch 82.21 | loss  0.26 | acc     0.91\n",
      "| epoch  16 |   960/ 1004 batches | lr 0.0882 | ms/batch 85.73 | loss  0.27 | acc     0.91\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  16 | time: 106.26s | valid loss  0.29 | valid acc     0.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  17 |    64/ 1004 batches | lr 0.0574 | ms/batch 84.74 | loss  0.28 | acc     0.92\n",
      "| epoch  17 |   128/ 1004 batches | lr 0.0574 | ms/batch 83.64 | loss  0.27 | acc     0.92\n",
      "| epoch  17 |   192/ 1004 batches | lr 0.0574 | ms/batch 83.36 | loss  0.26 | acc     0.91\n",
      "| epoch  17 |   256/ 1004 batches | lr 0.0574 | ms/batch 83.39 | loss  0.26 | acc     0.93\n",
      "| epoch  17 |   320/ 1004 batches | lr 0.0574 | ms/batch 83.36 | loss  0.27 | acc     0.92\n",
      "| epoch  17 |   384/ 1004 batches | lr 0.0574 | ms/batch 83.11 | loss  0.27 | acc     0.92\n",
      "| epoch  17 |   448/ 1004 batches | lr 0.0574 | ms/batch 83.24 | loss  0.26 | acc     0.92\n",
      "| epoch  17 |   512/ 1004 batches | lr 0.0574 | ms/batch 83.13 | loss  0.26 | acc     0.93\n",
      "| epoch  17 |   576/ 1004 batches | lr 0.0574 | ms/batch 83.37 | loss  0.26 | acc     0.92\n",
      "| epoch  17 |   640/ 1004 batches | lr 0.0574 | ms/batch 83.23 | loss  0.26 | acc     0.91\n",
      "| epoch  17 |   704/ 1004 batches | lr 0.0574 | ms/batch 83.28 | loss  0.26 | acc     0.92\n",
      "| epoch  17 |   768/ 1004 batches | lr 0.0574 | ms/batch 83.20 | loss  0.26 | acc     0.92\n",
      "| epoch  17 |   832/ 1004 batches | lr 0.0574 | ms/batch 83.38 | loss  0.26 | acc     0.93\n",
      "| epoch  17 |   896/ 1004 batches | lr 0.0574 | ms/batch 83.26 | loss  0.26 | acc     0.92\n",
      "| epoch  17 |   960/ 1004 batches | lr 0.0574 | ms/batch 83.47 | loss  0.27 | acc     0.91\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  17 | time: 107.82s | valid loss  0.29 | valid acc     0.96\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  18 |    64/ 1004 batches | lr 0.0574 | ms/batch 82.06 | loss  0.27 | acc     0.92\n",
      "| epoch  18 |   128/ 1004 batches | lr 0.0574 | ms/batch 81.67 | loss  0.27 | acc     0.91\n",
      "| epoch  18 |   192/ 1004 batches | lr 0.0574 | ms/batch 80.63 | loss  0.26 | acc     0.92\n",
      "| epoch  18 |   256/ 1004 batches | lr 0.0574 | ms/batch 80.77 | loss  0.27 | acc     0.92\n",
      "| epoch  18 |   320/ 1004 batches | lr 0.0574 | ms/batch 81.16 | loss  0.27 | acc     0.92\n",
      "| epoch  18 |   384/ 1004 batches | lr 0.0574 | ms/batch 81.43 | loss  0.26 | acc     0.92\n",
      "| epoch  18 |   448/ 1004 batches | lr 0.0574 | ms/batch 81.68 | loss  0.26 | acc     0.92\n",
      "| epoch  18 |   512/ 1004 batches | lr 0.0574 | ms/batch 81.81 | loss  0.26 | acc     0.93\n",
      "| epoch  18 |   576/ 1004 batches | lr 0.0574 | ms/batch 82.33 | loss  0.26 | acc     0.92\n",
      "| epoch  18 |   640/ 1004 batches | lr 0.0574 | ms/batch 81.95 | loss  0.26 | acc     0.91\n",
      "| epoch  18 |   704/ 1004 batches | lr 0.0574 | ms/batch 81.81 | loss  0.26 | acc     0.93\n",
      "| epoch  18 |   768/ 1004 batches | lr 0.0574 | ms/batch 81.69 | loss  0.26 | acc     0.93\n",
      "| epoch  18 |   832/ 1004 batches | lr 0.0574 | ms/batch 81.80 | loss  0.26 | acc     0.92\n",
      "| epoch  18 |   896/ 1004 batches | lr 0.0574 | ms/batch 81.95 | loss  0.26 | acc     0.92\n",
      "| epoch  18 |   960/ 1004 batches | lr 0.0574 | ms/batch 81.81 | loss  0.27 | acc     0.91\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  18 | time: 106.07s | valid loss  0.29 | valid acc     0.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  19 |    64/ 1004 batches | lr 0.0373 | ms/batch 89.75 | loss  0.27 | acc     0.91\n",
      "| epoch  19 |   128/ 1004 batches | lr 0.0373 | ms/batch 82.06 | loss  0.26 | acc     0.92\n",
      "| epoch  19 |   192/ 1004 batches | lr 0.0373 | ms/batch 82.07 | loss  0.26 | acc     0.92\n",
      "| epoch  19 |   256/ 1004 batches | lr 0.0373 | ms/batch 82.46 | loss  0.26 | acc     0.92\n",
      "| epoch  19 |   320/ 1004 batches | lr 0.0373 | ms/batch 82.24 | loss  0.27 | acc     0.92\n",
      "| epoch  19 |   384/ 1004 batches | lr 0.0373 | ms/batch 82.30 | loss  0.26 | acc     0.92\n",
      "| epoch  19 |   448/ 1004 batches | lr 0.0373 | ms/batch 82.07 | loss  0.26 | acc     0.92\n",
      "| epoch  19 |   512/ 1004 batches | lr 0.0373 | ms/batch 82.21 | loss  0.26 | acc     0.93\n",
      "| epoch  19 |   576/ 1004 batches | lr 0.0373 | ms/batch 82.18 | loss  0.26 | acc     0.92\n",
      "| epoch  19 |   640/ 1004 batches | lr 0.0373 | ms/batch 82.09 | loss  0.26 | acc     0.91\n",
      "| epoch  19 |   704/ 1004 batches | lr 0.0373 | ms/batch 82.20 | loss  0.26 | acc     0.93\n",
      "| epoch  19 |   768/ 1004 batches | lr 0.0373 | ms/batch 82.08 | loss  0.26 | acc     0.92\n",
      "| epoch  19 |   832/ 1004 batches | lr 0.0373 | ms/batch 82.20 | loss  0.26 | acc     0.93\n",
      "| epoch  19 |   896/ 1004 batches | lr 0.0373 | ms/batch 82.20 | loss  0.25 | acc     0.92\n",
      "| epoch  19 |   960/ 1004 batches | lr 0.0373 | ms/batch 82.07 | loss  0.27 | acc     0.91\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  19 | time: 106.83s | valid loss  0.29 | valid acc     0.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  20 |    64/ 1004 batches | lr 0.0373 | ms/batch 84.80 | loss  0.27 | acc     0.92\n",
      "| epoch  20 |   128/ 1004 batches | lr 0.0373 | ms/batch 83.49 | loss  0.26 | acc     0.91\n",
      "| epoch  20 |   192/ 1004 batches | lr 0.0373 | ms/batch 86.88 | loss  0.26 | acc     0.92\n",
      "| epoch  20 |   256/ 1004 batches | lr 0.0373 | ms/batch 83.11 | loss  0.26 | acc     0.92\n",
      "| epoch  20 |   320/ 1004 batches | lr 0.0373 | ms/batch 83.11 | loss  0.27 | acc     0.92\n",
      "| epoch  20 |   384/ 1004 batches | lr 0.0373 | ms/batch 83.24 | loss  0.26 | acc     0.93\n",
      "| epoch  20 |   448/ 1004 batches | lr 0.0373 | ms/batch 83.37 | loss  0.26 | acc     0.93\n",
      "| epoch  20 |   512/ 1004 batches | lr 0.0373 | ms/batch 83.38 | loss  0.26 | acc     0.93\n",
      "| epoch  20 |   576/ 1004 batches | lr 0.0373 | ms/batch 83.25 | loss  0.26 | acc     0.92\n",
      "| epoch  20 |   640/ 1004 batches | lr 0.0373 | ms/batch 83.10 | loss  0.26 | acc     0.91\n",
      "| epoch  20 |   704/ 1004 batches | lr 0.0373 | ms/batch 83.76 | loss  0.26 | acc     0.93\n",
      "| epoch  20 |   768/ 1004 batches | lr 0.0373 | ms/batch 83.15 | loss  0.26 | acc     0.92\n",
      "| epoch  20 |   832/ 1004 batches | lr 0.0373 | ms/batch 83.21 | loss  0.26 | acc     0.93\n",
      "| epoch  20 |   896/ 1004 batches | lr 0.0373 | ms/batch 83.24 | loss  0.25 | acc     0.92\n",
      "| epoch  20 |   960/ 1004 batches | lr 0.0373 | ms/batch 82.99 | loss  0.27 | acc     0.92\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  20 | time: 107.74s | valid loss  0.29 | valid acc     0.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  21 |    64/ 1004 batches | lr 0.0242 | ms/batch 85.46 | loss  0.27 | acc     0.92\n",
      "| epoch  21 |   128/ 1004 batches | lr 0.0242 | ms/batch 84.15 | loss  0.26 | acc     0.92\n",
      "| epoch  21 |   192/ 1004 batches | lr 0.0242 | ms/batch 84.15 | loss  0.26 | acc     0.92\n",
      "| epoch  21 |   256/ 1004 batches | lr 0.0242 | ms/batch 84.29 | loss  0.26 | acc     0.92\n",
      "| epoch  21 |   320/ 1004 batches | lr 0.0242 | ms/batch 88.72 | loss  0.27 | acc     0.92\n",
      "| epoch  21 |   384/ 1004 batches | lr 0.0242 | ms/batch 83.23 | loss  0.26 | acc     0.92\n",
      "| epoch  21 |   448/ 1004 batches | lr 0.0242 | ms/batch 83.24 | loss  0.26 | acc     0.92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  21 |   512/ 1004 batches | lr 0.0242 | ms/batch 83.01 | loss  0.26 | acc     0.93\n",
      "| epoch  21 |   576/ 1004 batches | lr 0.0242 | ms/batch 83.22 | loss  0.26 | acc     0.93\n",
      "| epoch  21 |   640/ 1004 batches | lr 0.0242 | ms/batch 83.25 | loss  0.26 | acc     0.91\n",
      "| epoch  21 |   704/ 1004 batches | lr 0.0242 | ms/batch 83.37 | loss  0.26 | acc     0.92\n",
      "| epoch  21 |   768/ 1004 batches | lr 0.0242 | ms/batch 83.24 | loss  0.26 | acc     0.93\n",
      "| epoch  21 |   832/ 1004 batches | lr 0.0242 | ms/batch 83.38 | loss  0.26 | acc     0.92\n",
      "| epoch  21 |   896/ 1004 batches | lr 0.0242 | ms/batch 83.38 | loss  0.25 | acc     0.91\n",
      "| epoch  21 |   960/ 1004 batches | lr 0.0242 | ms/batch 83.23 | loss  0.27 | acc     0.92\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  21 | time: 108.07s | valid loss  0.29 | valid acc     0.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  22 |    64/ 1004 batches | lr 0.0242 | ms/batch 84.54 | loss  0.27 | acc     0.92\n",
      "| epoch  22 |   128/ 1004 batches | lr 0.0242 | ms/batch 83.25 | loss  0.27 | acc     0.91\n",
      "| epoch  22 |   192/ 1004 batches | lr 0.0242 | ms/batch 83.24 | loss  0.26 | acc     0.92\n",
      "| epoch  22 |   256/ 1004 batches | lr 0.0242 | ms/batch 83.37 | loss  0.26 | acc     0.93\n",
      "| epoch  22 |   320/ 1004 batches | lr 0.0242 | ms/batch 83.38 | loss  0.27 | acc     0.92\n",
      "| epoch  22 |   384/ 1004 batches | lr 0.0242 | ms/batch 83.50 | loss  0.26 | acc     0.91\n",
      "| epoch  22 |   448/ 1004 batches | lr 0.0242 | ms/batch 87.42 | loss  0.26 | acc     0.92\n",
      "| epoch  22 |   512/ 1004 batches | lr 0.0242 | ms/batch 83.22 | loss  0.26 | acc     0.93\n",
      "| epoch  22 |   576/ 1004 batches | lr 0.0242 | ms/batch 83.26 | loss  0.26 | acc     0.92\n",
      "| epoch  22 |   640/ 1004 batches | lr 0.0242 | ms/batch 83.02 | loss  0.26 | acc     0.91\n",
      "| epoch  22 |   704/ 1004 batches | lr 0.0242 | ms/batch 83.23 | loss  0.26 | acc     0.93\n",
      "| epoch  22 |   768/ 1004 batches | lr 0.0242 | ms/batch 83.35 | loss  0.26 | acc     0.93\n",
      "| epoch  22 |   832/ 1004 batches | lr 0.0242 | ms/batch 83.49 | loss  0.26 | acc     0.92\n",
      "| epoch  22 |   896/ 1004 batches | lr 0.0242 | ms/batch 82.99 | loss  0.25 | acc     0.93\n",
      "| epoch  22 |   960/ 1004 batches | lr 0.0242 | ms/batch 83.10 | loss  0.27 | acc     0.91\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  22 | time: 107.66s | valid loss  0.29 | valid acc     0.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  23 |    64/ 1004 batches | lr 0.0158 | ms/batch 85.97 | loss  0.27 | acc     0.93\n",
      "| epoch  23 |   128/ 1004 batches | lr 0.0158 | ms/batch 84.15 | loss  0.27 | acc     0.91\n",
      "| epoch  23 |   192/ 1004 batches | lr 0.0158 | ms/batch 84.16 | loss  0.26 | acc     0.93\n",
      "| epoch  23 |   256/ 1004 batches | lr 0.0158 | ms/batch 84.01 | loss  0.26 | acc     0.93\n",
      "| epoch  23 |   320/ 1004 batches | lr 0.0158 | ms/batch 84.29 | loss  0.27 | acc     0.92\n",
      "| epoch  23 |   384/ 1004 batches | lr 0.0158 | ms/batch 84.62 | loss  0.26 | acc     0.93\n",
      "| epoch  23 |   448/ 1004 batches | lr 0.0158 | ms/batch 84.21 | loss  0.26 | acc     0.92\n",
      "| epoch  23 |   512/ 1004 batches | lr 0.0158 | ms/batch 84.28 | loss  0.26 | acc     0.92\n",
      "| epoch  23 |   576/ 1004 batches | lr 0.0158 | ms/batch 87.85 | loss  0.26 | acc     0.92\n",
      "| epoch  23 |   640/ 1004 batches | lr 0.0158 | ms/batch 83.06 | loss  0.26 | acc     0.91\n",
      "| epoch  23 |   704/ 1004 batches | lr 0.0158 | ms/batch 83.14 | loss  0.26 | acc     0.93\n",
      "| epoch  23 |   768/ 1004 batches | lr 0.0158 | ms/batch 83.11 | loss  0.26 | acc     0.92\n",
      "| epoch  23 |   832/ 1004 batches | lr 0.0158 | ms/batch 83.37 | loss  0.26 | acc     0.92\n",
      "| epoch  23 |   896/ 1004 batches | lr 0.0158 | ms/batch 83.11 | loss  0.25 | acc     0.91\n",
      "| epoch  23 |   960/ 1004 batches | lr 0.0158 | ms/batch 83.24 | loss  0.27 | acc     0.91\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  23 | time: 108.18s | valid loss  0.29 | valid acc     0.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  24 |    64/ 1004 batches | lr 0.0158 | ms/batch 84.47 | loss  0.27 | acc     0.92\n",
      "| epoch  24 |   128/ 1004 batches | lr 0.0158 | ms/batch 83.13 | loss  0.26 | acc     0.91\n",
      "| epoch  24 |   192/ 1004 batches | lr 0.0158 | ms/batch 83.12 | loss  0.26 | acc     0.92\n",
      "| epoch  24 |   256/ 1004 batches | lr 0.0158 | ms/batch 83.11 | loss  0.26 | acc     0.93\n",
      "| epoch  24 |   320/ 1004 batches | lr 0.0158 | ms/batch 83.25 | loss  0.27 | acc     0.92\n",
      "| epoch  24 |   384/ 1004 batches | lr 0.0158 | ms/batch 82.98 | loss  0.26 | acc     0.92\n",
      "| epoch  24 |   448/ 1004 batches | lr 0.0158 | ms/batch 82.98 | loss  0.26 | acc     0.92\n",
      "| epoch  24 |   512/ 1004 batches | lr 0.0158 | ms/batch 82.99 | loss  0.25 | acc     0.93\n",
      "| epoch  24 |   576/ 1004 batches | lr 0.0158 | ms/batch 83.25 | loss  0.26 | acc     0.93\n",
      "| epoch  24 |   640/ 1004 batches | lr 0.0158 | ms/batch 83.37 | loss  0.26 | acc     0.91\n",
      "| epoch  24 |   704/ 1004 batches | lr 0.0158 | ms/batch 87.41 | loss  0.26 | acc     0.93\n",
      "| epoch  24 |   768/ 1004 batches | lr 0.0158 | ms/batch 82.20 | loss  0.26 | acc     0.91\n",
      "| epoch  24 |   832/ 1004 batches | lr 0.0158 | ms/batch 82.20 | loss  0.25 | acc     0.93\n",
      "| epoch  24 |   896/ 1004 batches | lr 0.0158 | ms/batch 82.33 | loss  0.25 | acc     0.93\n",
      "| epoch  24 |   960/ 1004 batches | lr 0.0158 | ms/batch 82.08 | loss  0.27 | acc     0.92\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  24 | time: 107.36s | valid loss  0.29 | valid acc     0.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  25 |    64/ 1004 batches | lr 0.0102 | ms/batch 86.83 | loss  0.27 | acc     0.92\n",
      "| epoch  25 |   128/ 1004 batches | lr 0.0102 | ms/batch 85.58 | loss  0.26 | acc     0.91\n",
      "| epoch  25 |   192/ 1004 batches | lr 0.0102 | ms/batch 85.84 | loss  0.26 | acc     0.92\n",
      "| epoch  25 |   256/ 1004 batches | lr 0.0102 | ms/batch 85.48 | loss  0.26 | acc     0.94\n",
      "| epoch  25 |   320/ 1004 batches | lr 0.0102 | ms/batch 85.85 | loss  0.27 | acc     0.92\n",
      "| epoch  25 |   384/ 1004 batches | lr 0.0102 | ms/batch 85.62 | loss  0.26 | acc     0.92\n",
      "| epoch  25 |   448/ 1004 batches | lr 0.0102 | ms/batch 85.68 | loss  0.26 | acc     0.92\n",
      "| epoch  25 |   512/ 1004 batches | lr 0.0102 | ms/batch 85.58 | loss  0.25 | acc     0.93\n",
      "| epoch  25 |   576/ 1004 batches | lr 0.0102 | ms/batch 85.45 | loss  0.26 | acc     0.92\n",
      "| epoch  25 |   640/ 1004 batches | lr 0.0102 | ms/batch 84.28 | loss  0.26 | acc     0.92\n",
      "| epoch  25 |   704/ 1004 batches | lr 0.0102 | ms/batch 84.29 | loss  0.26 | acc     0.92\n",
      "| epoch  25 |   768/ 1004 batches | lr 0.0102 | ms/batch 84.16 | loss  0.26 | acc     0.92\n",
      "| epoch  25 |   832/ 1004 batches | lr 0.0102 | ms/batch 87.41 | loss  0.25 | acc     0.93\n",
      "| epoch  25 |   896/ 1004 batches | lr 0.0102 | ms/batch 83.37 | loss  0.25 | acc     0.91\n",
      "| epoch  25 |   960/ 1004 batches | lr 0.0102 | ms/batch 82.97 | loss  0.27 | acc     0.91\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  25 | time: 109.17s | valid loss  0.29 | valid acc     0.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  26 |    64/ 1004 batches | lr 0.0102 | ms/batch 82.12 | loss  0.27 | acc     0.92\n",
      "| epoch  26 |   128/ 1004 batches | lr 0.0102 | ms/batch 80.64 | loss  0.26 | acc     0.92\n",
      "| epoch  26 |   192/ 1004 batches | lr 0.0102 | ms/batch 80.77 | loss  0.26 | acc     0.91\n",
      "| epoch  26 |   256/ 1004 batches | lr 0.0102 | ms/batch 81.29 | loss  0.26 | acc     0.93\n",
      "| epoch  26 |   320/ 1004 batches | lr 0.0102 | ms/batch 81.81 | loss  0.27 | acc     0.92\n",
      "| epoch  26 |   384/ 1004 batches | lr 0.0102 | ms/batch 81.68 | loss  0.26 | acc     0.91\n",
      "| epoch  26 |   448/ 1004 batches | lr 0.0102 | ms/batch 81.81 | loss  0.25 | acc     0.92\n",
      "| epoch  26 |   512/ 1004 batches | lr 0.0102 | ms/batch 82.34 | loss  0.25 | acc     0.93\n",
      "| epoch  26 |   576/ 1004 batches | lr 0.0102 | ms/batch 82.20 | loss  0.26 | acc     0.93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  26 |   640/ 1004 batches | lr 0.0102 | ms/batch 82.07 | loss  0.26 | acc     0.92\n",
      "| epoch  26 |   704/ 1004 batches | lr 0.0102 | ms/batch 82.52 | loss  0.26 | acc     0.93\n",
      "| epoch  26 |   768/ 1004 batches | lr 0.0102 | ms/batch 82.15 | loss  0.25 | acc     0.93\n",
      "| epoch  26 |   832/ 1004 batches | lr 0.0102 | ms/batch 82.07 | loss  0.26 | acc     0.93\n",
      "| epoch  26 |   896/ 1004 batches | lr 0.0102 | ms/batch 82.46 | loss  0.25 | acc     0.92\n",
      "| epoch  26 |   960/ 1004 batches | lr 0.0102 | ms/batch 86.11 | loss  0.27 | acc     0.91\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  26 | time: 106.41s | valid loss  0.29 | valid acc     0.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  27 |    64/ 1004 batches | lr 0.0067 | ms/batch 87.22 | loss  0.27 | acc     0.92\n",
      "| epoch  27 |   128/ 1004 batches | lr 0.0067 | ms/batch 85.45 | loss  0.26 | acc     0.92\n",
      "| epoch  27 |   192/ 1004 batches | lr 0.0067 | ms/batch 85.58 | loss  0.26 | acc     0.93\n",
      "| epoch  27 |   256/ 1004 batches | lr 0.0067 | ms/batch 85.58 | loss  0.26 | acc     0.93\n",
      "| epoch  27 |   320/ 1004 batches | lr 0.0067 | ms/batch 85.70 | loss  0.27 | acc     0.93\n",
      "| epoch  27 |   384/ 1004 batches | lr 0.0067 | ms/batch 85.60 | loss  0.26 | acc     0.92\n",
      "| epoch  27 |   448/ 1004 batches | lr 0.0067 | ms/batch 85.45 | loss  0.25 | acc     0.92\n",
      "| epoch  27 |   512/ 1004 batches | lr 0.0067 | ms/batch 85.89 | loss  0.25 | acc     0.93\n",
      "| epoch  27 |   576/ 1004 batches | lr 0.0067 | ms/batch 85.67 | loss  0.26 | acc     0.92\n",
      "| epoch  27 |   640/ 1004 batches | lr 0.0067 | ms/batch 85.44 | loss  0.26 | acc     0.92\n",
      "| epoch  27 |   704/ 1004 batches | lr 0.0067 | ms/batch 85.32 | loss  0.26 | acc     0.94\n",
      "| epoch  27 |   768/ 1004 batches | lr 0.0067 | ms/batch 85.45 | loss  0.25 | acc     0.93\n",
      "| epoch  27 |   832/ 1004 batches | lr 0.0067 | ms/batch 85.51 | loss  0.25 | acc     0.93\n",
      "| epoch  27 |   896/ 1004 batches | lr 0.0067 | ms/batch 85.40 | loss  0.25 | acc     0.92\n",
      "| epoch  27 |   960/ 1004 batches | lr 0.0067 | ms/batch 85.46 | loss  0.27 | acc     0.91\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  27 | time: 110.80s | valid loss  0.29 | valid acc     0.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  28 |    64/ 1004 batches | lr 0.0067 | ms/batch 81.96 | loss  0.27 | acc     0.93\n",
      "| epoch  28 |   128/ 1004 batches | lr 0.0067 | ms/batch 80.78 | loss  0.26 | acc     0.92\n",
      "| epoch  28 |   192/ 1004 batches | lr 0.0067 | ms/batch 80.90 | loss  0.26 | acc     0.92\n",
      "| epoch  28 |   256/ 1004 batches | lr 0.0067 | ms/batch 80.77 | loss  0.26 | acc     0.92\n",
      "| epoch  28 |   320/ 1004 batches | lr 0.0067 | ms/batch 80.64 | loss  0.27 | acc     0.92\n",
      "| epoch  28 |   384/ 1004 batches | lr 0.0067 | ms/batch 81.02 | loss  0.26 | acc     0.93\n",
      "| epoch  28 |   448/ 1004 batches | lr 0.0067 | ms/batch 81.69 | loss  0.26 | acc     0.92\n",
      "| epoch  28 |   512/ 1004 batches | lr 0.0067 | ms/batch 81.95 | loss  0.25 | acc     0.93\n",
      "| epoch  28 |   576/ 1004 batches | lr 0.0067 | ms/batch 82.07 | loss  0.26 | acc     0.92\n",
      "| epoch  28 |   640/ 1004 batches | lr 0.0067 | ms/batch 82.20 | loss  0.25 | acc     0.92\n",
      "| epoch  28 |   704/ 1004 batches | lr 0.0067 | ms/batch 82.33 | loss  0.26 | acc     0.94\n",
      "| epoch  28 |   768/ 1004 batches | lr 0.0067 | ms/batch 82.36 | loss  0.25 | acc     0.92\n",
      "| epoch  28 |   832/ 1004 batches | lr 0.0067 | ms/batch 82.30 | loss  0.25 | acc     0.92\n",
      "| epoch  28 |   896/ 1004 batches | lr 0.0067 | ms/batch 82.22 | loss  0.25 | acc     0.92\n",
      "| epoch  28 |   960/ 1004 batches | lr 0.0067 | ms/batch 82.19 | loss  0.27 | acc     0.91\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  28 | time: 105.86s | valid loss  0.29 | valid acc     0.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  29 |    64/ 1004 batches | lr 0.0043 | ms/batch 89.63 | loss  0.27 | acc     0.92\n",
      "| epoch  29 |   128/ 1004 batches | lr 0.0043 | ms/batch 83.50 | loss  0.26 | acc     0.92\n",
      "| epoch  29 |   192/ 1004 batches | lr 0.0043 | ms/batch 83.42 | loss  0.26 | acc     0.92\n",
      "| epoch  29 |   256/ 1004 batches | lr 0.0043 | ms/batch 83.44 | loss  0.26 | acc     0.92\n",
      "| epoch  29 |   320/ 1004 batches | lr 0.0043 | ms/batch 83.40 | loss  0.27 | acc     0.92\n",
      "| epoch  29 |   384/ 1004 batches | lr 0.0043 | ms/batch 83.35 | loss  0.26 | acc     0.92\n",
      "| epoch  29 |   448/ 1004 batches | lr 0.0043 | ms/batch 83.23 | loss  0.26 | acc     0.93\n",
      "| epoch  29 |   512/ 1004 batches | lr 0.0043 | ms/batch 83.39 | loss  0.25 | acc     0.93\n",
      "| epoch  29 |   576/ 1004 batches | lr 0.0043 | ms/batch 83.38 | loss  0.26 | acc     0.92\n",
      "| epoch  29 |   640/ 1004 batches | lr 0.0043 | ms/batch 83.37 | loss  0.26 | acc     0.92\n",
      "| epoch  29 |   704/ 1004 batches | lr 0.0043 | ms/batch 83.37 | loss  0.26 | acc     0.94\n",
      "| epoch  29 |   768/ 1004 batches | lr 0.0043 | ms/batch 83.38 | loss  0.26 | acc     0.92\n",
      "| epoch  29 |   832/ 1004 batches | lr 0.0043 | ms/batch 83.11 | loss  0.25 | acc     0.92\n",
      "| epoch  29 |   896/ 1004 batches | lr 0.0043 | ms/batch 83.24 | loss  0.25 | acc     0.92\n",
      "| epoch  29 |   960/ 1004 batches | lr 0.0043 | ms/batch 83.24 | loss  0.27 | acc     0.91\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  29 | time: 107.86s | valid loss  0.29 | valid acc     0.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  30 |    64/ 1004 batches | lr 0.0043 | ms/batch 83.27 | loss  0.27 | acc     0.92\n",
      "| epoch  30 |   128/ 1004 batches | lr 0.0043 | ms/batch 82.20 | loss  0.26 | acc     0.92\n",
      "| epoch  30 |   192/ 1004 batches | lr 0.0043 | ms/batch 86.78 | loss  0.26 | acc     0.92\n",
      "| epoch  30 |   256/ 1004 batches | lr 0.0043 | ms/batch 81.92 | loss  0.26 | acc     0.93\n",
      "| epoch  30 |   320/ 1004 batches | lr 0.0043 | ms/batch 81.82 | loss  0.27 | acc     0.92\n",
      "| epoch  30 |   384/ 1004 batches | lr 0.0043 | ms/batch 81.83 | loss  0.26 | acc     0.92\n",
      "| epoch  30 |   448/ 1004 batches | lr 0.0043 | ms/batch 81.78 | loss  0.26 | acc     0.93\n",
      "| epoch  30 |   512/ 1004 batches | lr 0.0043 | ms/batch 81.95 | loss  0.25 | acc     0.93\n",
      "| epoch  30 |   576/ 1004 batches | lr 0.0043 | ms/batch 81.69 | loss  0.26 | acc     0.92\n",
      "| epoch  30 |   640/ 1004 batches | lr 0.0043 | ms/batch 81.68 | loss  0.26 | acc     0.92\n",
      "| epoch  30 |   704/ 1004 batches | lr 0.0043 | ms/batch 81.68 | loss  0.26 | acc     0.93\n",
      "| epoch  30 |   768/ 1004 batches | lr 0.0043 | ms/batch 81.94 | loss  0.25 | acc     0.92\n",
      "| epoch  30 |   832/ 1004 batches | lr 0.0043 | ms/batch 81.68 | loss  0.26 | acc     0.93\n",
      "| epoch  30 |   896/ 1004 batches | lr 0.0043 | ms/batch 81.82 | loss  0.25 | acc     0.92\n",
      "| epoch  30 |   960/ 1004 batches | lr 0.0043 | ms/batch 81.94 | loss  0.27 | acc     0.91\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  30 | time: 106.37s | valid loss  0.29 | valid acc     0.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  31 |    64/ 1004 batches | lr 0.0028 | ms/batch 85.43 | loss  0.27 | acc     0.92\n",
      "| epoch  31 |   128/ 1004 batches | lr 0.0028 | ms/batch 84.15 | loss  0.26 | acc     0.92\n",
      "| epoch  31 |   192/ 1004 batches | lr 0.0028 | ms/batch 84.02 | loss  0.26 | acc     0.92\n",
      "| epoch  31 |   256/ 1004 batches | lr 0.0028 | ms/batch 84.41 | loss  0.26 | acc     0.94\n",
      "| epoch  31 |   320/ 1004 batches | lr 0.0028 | ms/batch 87.27 | loss  0.27 | acc     0.92\n",
      "| epoch  31 |   384/ 1004 batches | lr 0.0028 | ms/batch 83.51 | loss  0.26 | acc     0.92\n",
      "| epoch  31 |   448/ 1004 batches | lr 0.0028 | ms/batch 83.10 | loss  0.26 | acc     0.92\n",
      "| epoch  31 |   512/ 1004 batches | lr 0.0028 | ms/batch 83.52 | loss  0.25 | acc     0.93\n",
      "| epoch  31 |   576/ 1004 batches | lr 0.0028 | ms/batch 83.50 | loss  0.26 | acc     0.93\n",
      "| epoch  31 |   640/ 1004 batches | lr 0.0028 | ms/batch 83.64 | loss  0.25 | acc     0.92\n",
      "| epoch  31 |   704/ 1004 batches | lr 0.0028 | ms/batch 83.24 | loss  0.26 | acc     0.93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  31 |   768/ 1004 batches | lr 0.0028 | ms/batch 83.38 | loss  0.26 | acc     0.93\n",
      "| epoch  31 |   832/ 1004 batches | lr 0.0028 | ms/batch 83.37 | loss  0.26 | acc     0.92\n",
      "| epoch  31 |   896/ 1004 batches | lr 0.0028 | ms/batch 83.76 | loss  0.25 | acc     0.92\n",
      "| epoch  31 |   960/ 1004 batches | lr 0.0028 | ms/batch 83.25 | loss  0.27 | acc     0.92\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  31 | time: 108.11s | valid loss  0.29 | valid acc     0.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  32 |    64/ 1004 batches | lr 0.0028 | ms/batch 82.06 | loss  0.27 | acc     0.92\n",
      "| epoch  32 |   128/ 1004 batches | lr 0.0028 | ms/batch 80.77 | loss  0.26 | acc     0.91\n",
      "| epoch  32 |   192/ 1004 batches | lr 0.0028 | ms/batch 80.91 | loss  0.26 | acc     0.92\n",
      "| epoch  32 |   256/ 1004 batches | lr 0.0028 | ms/batch 80.90 | loss  0.26 | acc     0.92\n",
      "| epoch  32 |   320/ 1004 batches | lr 0.0028 | ms/batch 80.76 | loss  0.27 | acc     0.91\n",
      "| epoch  32 |   384/ 1004 batches | lr 0.0028 | ms/batch 80.90 | loss  0.26 | acc     0.92\n",
      "| epoch  32 |   448/ 1004 batches | lr 0.0028 | ms/batch 84.16 | loss  0.26 | acc     0.92\n",
      "| epoch  32 |   512/ 1004 batches | lr 0.0028 | ms/batch 81.17 | loss  0.25 | acc     0.93\n",
      "| epoch  32 |   576/ 1004 batches | lr 0.0028 | ms/batch 81.14 | loss  0.25 | acc     0.93\n",
      "| epoch  32 |   640/ 1004 batches | lr 0.0028 | ms/batch 81.43 | loss  0.25 | acc     0.92\n",
      "| epoch  32 |   704/ 1004 batches | lr 0.0028 | ms/batch 81.81 | loss  0.26 | acc     0.94\n",
      "| epoch  32 |   768/ 1004 batches | lr 0.0028 | ms/batch 82.19 | loss  0.25 | acc     0.93\n",
      "| epoch  32 |   832/ 1004 batches | lr 0.0028 | ms/batch 82.34 | loss  0.26 | acc     0.93\n",
      "| epoch  32 |   896/ 1004 batches | lr 0.0028 | ms/batch 82.35 | loss  0.25 | acc     0.92\n",
      "| epoch  32 |   960/ 1004 batches | lr 0.0028 | ms/batch 82.20 | loss  0.27 | acc     0.91\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  32 | time: 106.07s | valid loss  0.29 | valid acc     0.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  33 |    64/ 1004 batches | lr 0.0018 | ms/batch 84.60 | loss  0.27 | acc     0.92\n",
      "| epoch  33 |   128/ 1004 batches | lr 0.0018 | ms/batch 83.38 | loss  0.26 | acc     0.91\n",
      "| epoch  33 |   192/ 1004 batches | lr 0.0018 | ms/batch 83.36 | loss  0.26 | acc     0.93\n",
      "| epoch  33 |   256/ 1004 batches | lr 0.0018 | ms/batch 83.51 | loss  0.26 | acc     0.93\n",
      "| epoch  33 |   320/ 1004 batches | lr 0.0018 | ms/batch 83.50 | loss  0.27 | acc     0.91\n",
      "| epoch  33 |   384/ 1004 batches | lr 0.0018 | ms/batch 83.25 | loss  0.26 | acc     0.93\n",
      "| epoch  33 |   448/ 1004 batches | lr 0.0018 | ms/batch 83.24 | loss  0.25 | acc     0.93\n",
      "| epoch  33 |   512/ 1004 batches | lr 0.0018 | ms/batch 83.38 | loss  0.25 | acc     0.93\n",
      "| epoch  33 |   576/ 1004 batches | lr 0.0018 | ms/batch 86.11 | loss  0.26 | acc     0.92\n",
      "| epoch  33 |   640/ 1004 batches | lr 0.0018 | ms/batch 83.38 | loss  0.25 | acc     0.92\n",
      "| epoch  33 |   704/ 1004 batches | lr 0.0018 | ms/batch 83.48 | loss  0.26 | acc     0.93\n",
      "| epoch  33 |   768/ 1004 batches | lr 0.0018 | ms/batch 83.50 | loss  0.25 | acc     0.92\n",
      "| epoch  33 |   832/ 1004 batches | lr 0.0018 | ms/batch 83.50 | loss  0.26 | acc     0.92\n",
      "| epoch  33 |   896/ 1004 batches | lr 0.0018 | ms/batch 83.38 | loss  0.25 | acc     0.92\n",
      "| epoch  33 |   960/ 1004 batches | lr 0.0018 | ms/batch 83.37 | loss  0.27 | acc     0.91\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  33 | time: 107.77s | valid loss  0.29 | valid acc     0.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  34 |    64/ 1004 batches | lr 0.0018 | ms/batch 84.20 | loss  0.27 | acc     0.92\n",
      "| epoch  34 |   128/ 1004 batches | lr 0.0018 | ms/batch 82.18 | loss  0.26 | acc     0.91\n",
      "| epoch  34 |   192/ 1004 batches | lr 0.0018 | ms/batch 82.07 | loss  0.26 | acc     0.93\n",
      "| epoch  34 |   256/ 1004 batches | lr 0.0018 | ms/batch 81.95 | loss  0.26 | acc     0.93\n",
      "| epoch  34 |   320/ 1004 batches | lr 0.0018 | ms/batch 81.94 | loss  0.27 | acc     0.92\n",
      "| epoch  34 |   384/ 1004 batches | lr 0.0018 | ms/batch 82.20 | loss  0.26 | acc     0.91\n",
      "| epoch  34 |   448/ 1004 batches | lr 0.0018 | ms/batch 82.46 | loss  0.26 | acc     0.92\n",
      "| epoch  34 |   512/ 1004 batches | lr 0.0018 | ms/batch 82.21 | loss  0.25 | acc     0.92\n",
      "| epoch  34 |   576/ 1004 batches | lr 0.0018 | ms/batch 82.08 | loss  0.26 | acc     0.93\n",
      "| epoch  34 |   640/ 1004 batches | lr 0.0018 | ms/batch 82.20 | loss  0.26 | acc     0.92\n",
      "| epoch  34 |   704/ 1004 batches | lr 0.0018 | ms/batch 84.99 | loss  0.26 | acc     0.93\n",
      "| epoch  34 |   768/ 1004 batches | lr 0.0018 | ms/batch 82.16 | loss  0.25 | acc     0.93\n",
      "| epoch  34 |   832/ 1004 batches | lr 0.0018 | ms/batch 82.33 | loss  0.26 | acc     0.92\n",
      "| epoch  34 |   896/ 1004 batches | lr 0.0018 | ms/batch 82.45 | loss  0.25 | acc     0.92\n",
      "| epoch  34 |   960/ 1004 batches | lr 0.0018 | ms/batch 82.35 | loss  0.26 | acc     0.92\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  34 | time: 106.69s | valid loss  0.29 | valid acc     0.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  35 |    64/ 1004 batches | lr 0.0012 | ms/batch 85.56 | loss  0.27 | acc     0.92\n",
      "| epoch  35 |   128/ 1004 batches | lr 0.0012 | ms/batch 84.29 | loss  0.26 | acc     0.91\n",
      "| epoch  35 |   192/ 1004 batches | lr 0.0012 | ms/batch 84.28 | loss  0.26 | acc     0.92\n",
      "| epoch  35 |   256/ 1004 batches | lr 0.0012 | ms/batch 84.42 | loss  0.26 | acc     0.93\n",
      "| epoch  35 |   320/ 1004 batches | lr 0.0012 | ms/batch 84.28 | loss  0.27 | acc     0.93\n",
      "| epoch  35 |   384/ 1004 batches | lr 0.0012 | ms/batch 84.15 | loss  0.26 | acc     0.92\n",
      "| epoch  35 |   448/ 1004 batches | lr 0.0012 | ms/batch 84.55 | loss  0.25 | acc     0.92\n",
      "| epoch  35 |   512/ 1004 batches | lr 0.0012 | ms/batch 84.41 | loss  0.25 | acc     0.93\n",
      "| epoch  35 |   576/ 1004 batches | lr 0.0012 | ms/batch 84.29 | loss  0.26 | acc     0.91\n",
      "| epoch  35 |   640/ 1004 batches | lr 0.0012 | ms/batch 84.15 | loss  0.26 | acc     0.92\n",
      "| epoch  35 |   704/ 1004 batches | lr 0.0012 | ms/batch 84.16 | loss  0.26 | acc     0.93\n",
      "| epoch  35 |   768/ 1004 batches | lr 0.0012 | ms/batch 84.28 | loss  0.25 | acc     0.93\n",
      "| epoch  35 |   832/ 1004 batches | lr 0.0012 | ms/batch 87.28 | loss  0.26 | acc     0.91\n",
      "| epoch  35 |   896/ 1004 batches | lr 0.0012 | ms/batch 83.90 | loss  0.25 | acc     0.92\n",
      "| epoch  35 |   960/ 1004 batches | lr 0.0012 | ms/batch 83.62 | loss  0.27 | acc     0.92\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  35 | time: 108.62s | valid loss  0.29 | valid acc     0.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  36 |    64/ 1004 batches | lr 0.0012 | ms/batch 82.11 | loss  0.27 | acc     0.93\n",
      "| epoch  36 |   128/ 1004 batches | lr 0.0012 | ms/batch 80.81 | loss  0.26 | acc     0.91\n",
      "| epoch  36 |   192/ 1004 batches | lr 0.0012 | ms/batch 80.60 | loss  0.26 | acc     0.92\n",
      "| epoch  36 |   256/ 1004 batches | lr 0.0012 | ms/batch 80.91 | loss  0.26 | acc     0.92\n",
      "| epoch  36 |   320/ 1004 batches | lr 0.0012 | ms/batch 81.55 | loss  0.27 | acc     0.92\n",
      "| epoch  36 |   384/ 1004 batches | lr 0.0012 | ms/batch 81.68 | loss  0.26 | acc     0.92\n",
      "| epoch  36 |   448/ 1004 batches | lr 0.0012 | ms/batch 81.69 | loss  0.26 | acc     0.92\n",
      "| epoch  36 |   512/ 1004 batches | lr 0.0012 | ms/batch 81.93 | loss  0.25 | acc     0.93\n",
      "| epoch  36 |   576/ 1004 batches | lr 0.0012 | ms/batch 81.82 | loss  0.26 | acc     0.92\n",
      "| epoch  36 |   640/ 1004 batches | lr 0.0012 | ms/batch 81.68 | loss  0.26 | acc     0.92\n",
      "| epoch  36 |   704/ 1004 batches | lr 0.0012 | ms/batch 81.81 | loss  0.26 | acc     0.93\n",
      "| epoch  36 |   768/ 1004 batches | lr 0.0012 | ms/batch 81.69 | loss  0.26 | acc     0.92\n",
      "| epoch  36 |   832/ 1004 batches | lr 0.0012 | ms/batch 81.69 | loss  0.26 | acc     0.92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  36 |   896/ 1004 batches | lr 0.0012 | ms/batch 81.80 | loss  0.25 | acc     0.92\n",
      "| epoch  36 |   960/ 1004 batches | lr 0.0012 | ms/batch 86.50 | loss  0.27 | acc     0.92\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  36 | time: 106.20s | valid loss  0.29 | valid acc     0.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  37 |    64/ 1004 batches | lr 0.0008 | ms/batch 85.72 | loss  0.27 | acc     0.92\n",
      "| epoch  37 |   128/ 1004 batches | lr 0.0008 | ms/batch 84.25 | loss  0.26 | acc     0.91\n",
      "| epoch  37 |   192/ 1004 batches | lr 0.0008 | ms/batch 84.30 | loss  0.26 | acc     0.92\n",
      "| epoch  37 |   256/ 1004 batches | lr 0.0008 | ms/batch 84.29 | loss  0.26 | acc     0.93\n",
      "| epoch  37 |   320/ 1004 batches | lr 0.0008 | ms/batch 84.26 | loss  0.27 | acc     0.92\n",
      "| epoch  37 |   384/ 1004 batches | lr 0.0008 | ms/batch 84.03 | loss  0.26 | acc     0.92\n",
      "| epoch  37 |   448/ 1004 batches | lr 0.0008 | ms/batch 84.15 | loss  0.25 | acc     0.92\n",
      "| epoch  37 |   512/ 1004 batches | lr 0.0008 | ms/batch 84.28 | loss  0.25 | acc     0.93\n",
      "| epoch  37 |   576/ 1004 batches | lr 0.0008 | ms/batch 84.17 | loss  0.26 | acc     0.92\n",
      "| epoch  37 |   640/ 1004 batches | lr 0.0008 | ms/batch 84.30 | loss  0.26 | acc     0.92\n",
      "| epoch  37 |   704/ 1004 batches | lr 0.0008 | ms/batch 84.51 | loss  0.26 | acc     0.93\n",
      "| epoch  37 |   768/ 1004 batches | lr 0.0008 | ms/batch 84.03 | loss  0.26 | acc     0.92\n",
      "| epoch  37 |   832/ 1004 batches | lr 0.0008 | ms/batch 84.15 | loss  0.25 | acc     0.93\n",
      "| epoch  37 |   896/ 1004 batches | lr 0.0008 | ms/batch 84.43 | loss  0.25 | acc     0.92\n",
      "| epoch  37 |   960/ 1004 batches | lr 0.0008 | ms/batch 84.40 | loss  0.27 | acc     0.91\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  37 | time: 109.03s | valid loss  0.29 | valid acc     0.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  38 |    64/ 1004 batches | lr 0.0008 | ms/batch 84.70 | loss  0.27 | acc     0.92\n",
      "| epoch  38 |   128/ 1004 batches | lr 0.0008 | ms/batch 83.63 | loss  0.26 | acc     0.90\n",
      "| epoch  38 |   192/ 1004 batches | lr 0.0008 | ms/batch 83.50 | loss  0.26 | acc     0.92\n",
      "| epoch  38 |   256/ 1004 batches | lr 0.0008 | ms/batch 83.50 | loss  0.26 | acc     0.92\n",
      "| epoch  38 |   320/ 1004 batches | lr 0.0008 | ms/batch 83.37 | loss  0.27 | acc     0.92\n",
      "| epoch  38 |   384/ 1004 batches | lr 0.0008 | ms/batch 83.42 | loss  0.26 | acc     0.92\n",
      "| epoch  38 |   448/ 1004 batches | lr 0.0008 | ms/batch 83.33 | loss  0.25 | acc     0.92\n",
      "| epoch  38 |   512/ 1004 batches | lr 0.0008 | ms/batch 83.25 | loss  0.25 | acc     0.93\n",
      "| epoch  38 |   576/ 1004 batches | lr 0.0008 | ms/batch 83.24 | loss  0.26 | acc     0.92\n",
      "| epoch  38 |   640/ 1004 batches | lr 0.0008 | ms/batch 83.36 | loss  0.25 | acc     0.92\n",
      "| epoch  38 |   704/ 1004 batches | lr 0.0008 | ms/batch 83.26 | loss  0.26 | acc     0.93\n",
      "| epoch  38 |   768/ 1004 batches | lr 0.0008 | ms/batch 83.24 | loss  0.25 | acc     0.93\n",
      "| epoch  38 |   832/ 1004 batches | lr 0.0008 | ms/batch 83.37 | loss  0.26 | acc     0.93\n",
      "| epoch  38 |   896/ 1004 batches | lr 0.0008 | ms/batch 83.39 | loss  0.25 | acc     0.92\n",
      "| epoch  38 |   960/ 1004 batches | lr 0.0008 | ms/batch 83.36 | loss  0.27 | acc     0.92\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  38 | time: 107.63s | valid loss  0.29 | valid acc     0.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  39 |    64/ 1004 batches | lr 0.0005 | ms/batch 88.12 | loss  0.27 | acc     0.92\n",
      "| epoch  39 |   128/ 1004 batches | lr 0.0005 | ms/batch 83.24 | loss  0.26 | acc     0.91\n",
      "| epoch  39 |   192/ 1004 batches | lr 0.0005 | ms/batch 83.24 | loss  0.26 | acc     0.91\n",
      "| epoch  39 |   256/ 1004 batches | lr 0.0005 | ms/batch 83.41 | loss  0.26 | acc     0.92\n",
      "| epoch  39 |   320/ 1004 batches | lr 0.0005 | ms/batch 83.34 | loss  0.27 | acc     0.92\n",
      "| epoch  39 |   384/ 1004 batches | lr 0.0005 | ms/batch 83.39 | loss  0.26 | acc     0.92\n",
      "| epoch  39 |   448/ 1004 batches | lr 0.0005 | ms/batch 83.36 | loss  0.26 | acc     0.92\n",
      "| epoch  39 |   512/ 1004 batches | lr 0.0005 | ms/batch 83.38 | loss  0.25 | acc     0.93\n",
      "| epoch  39 |   576/ 1004 batches | lr 0.0005 | ms/batch 83.64 | loss  0.26 | acc     0.92\n",
      "| epoch  39 |   640/ 1004 batches | lr 0.0005 | ms/batch 83.28 | loss  0.26 | acc     0.91\n",
      "| epoch  39 |   704/ 1004 batches | lr 0.0005 | ms/batch 83.33 | loss  0.26 | acc     0.93\n",
      "| epoch  39 |   768/ 1004 batches | lr 0.0005 | ms/batch 83.11 | loss  0.25 | acc     0.92\n",
      "| epoch  39 |   832/ 1004 batches | lr 0.0005 | ms/batch 83.13 | loss  0.25 | acc     0.92\n",
      "| epoch  39 |   896/ 1004 batches | lr 0.0005 | ms/batch 83.49 | loss  0.25 | acc     0.92\n",
      "| epoch  39 |   960/ 1004 batches | lr 0.0005 | ms/batch 83.37 | loss  0.27 | acc     0.92\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  39 | time: 107.80s | valid loss  0.29 | valid acc     0.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  40 |    64/ 1004 batches | lr 0.0005 | ms/batch 82.04 | loss  0.27 | acc     0.93\n",
      "| epoch  40 |   128/ 1004 batches | lr 0.0005 | ms/batch 80.78 | loss  0.26 | acc     0.91\n",
      "| epoch  40 |   192/ 1004 batches | lr 0.0005 | ms/batch 85.07 | loss  0.26 | acc     0.92\n",
      "| epoch  40 |   256/ 1004 batches | lr 0.0005 | ms/batch 81.29 | loss  0.26 | acc     0.93\n",
      "| epoch  40 |   320/ 1004 batches | lr 0.0005 | ms/batch 81.41 | loss  0.27 | acc     0.92\n",
      "| epoch  40 |   384/ 1004 batches | lr 0.0005 | ms/batch 81.68 | loss  0.26 | acc     0.92\n",
      "| epoch  40 |   448/ 1004 batches | lr 0.0005 | ms/batch 81.68 | loss  0.25 | acc     0.93\n",
      "| epoch  40 |   512/ 1004 batches | lr 0.0005 | ms/batch 81.71 | loss  0.25 | acc     0.94\n",
      "| epoch  40 |   576/ 1004 batches | lr 0.0005 | ms/batch 81.66 | loss  0.26 | acc     0.92\n",
      "| epoch  40 |   640/ 1004 batches | lr 0.0005 | ms/batch 81.81 | loss  0.25 | acc     0.91\n",
      "| epoch  40 |   704/ 1004 batches | lr 0.0005 | ms/batch 82.09 | loss  0.26 | acc     0.93\n",
      "| epoch  40 |   768/ 1004 batches | lr 0.0005 | ms/batch 81.83 | loss  0.25 | acc     0.91\n",
      "| epoch  40 |   832/ 1004 batches | lr 0.0005 | ms/batch 81.90 | loss  0.25 | acc     0.92\n",
      "| epoch  40 |   896/ 1004 batches | lr 0.0005 | ms/batch 82.35 | loss  0.25 | acc     0.93\n",
      "| epoch  40 |   960/ 1004 batches | lr 0.0005 | ms/batch 82.19 | loss  0.26 | acc     0.91\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  40 | time: 106.15s | valid loss  0.29 | valid acc     0.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  41 |    64/ 1004 batches | lr 0.0003 | ms/batch 83.46 | loss  0.27 | acc     0.92\n",
      "| epoch  41 |   128/ 1004 batches | lr 0.0003 | ms/batch 82.39 | loss  0.26 | acc     0.91\n",
      "| epoch  41 |   192/ 1004 batches | lr 0.0003 | ms/batch 82.27 | loss  0.26 | acc     0.92\n",
      "| epoch  41 |   256/ 1004 batches | lr 0.0003 | ms/batch 81.94 | loss  0.26 | acc     0.93\n",
      "| epoch  41 |   320/ 1004 batches | lr 0.0003 | ms/batch 85.51 | loss  0.27 | acc     0.92\n",
      "| epoch  41 |   384/ 1004 batches | lr 0.0003 | ms/batch 82.29 | loss  0.26 | acc     0.93\n",
      "| epoch  41 |   448/ 1004 batches | lr 0.0003 | ms/batch 82.06 | loss  0.25 | acc     0.93\n",
      "| epoch  41 |   512/ 1004 batches | lr 0.0003 | ms/batch 82.27 | loss  0.25 | acc     0.94\n",
      "| epoch  41 |   576/ 1004 batches | lr 0.0003 | ms/batch 82.56 | loss  0.26 | acc     0.92\n",
      "| epoch  41 |   640/ 1004 batches | lr 0.0003 | ms/batch 82.30 | loss  0.26 | acc     0.92\n",
      "| epoch  41 |   704/ 1004 batches | lr 0.0003 | ms/batch 82.20 | loss  0.26 | acc     0.93\n",
      "| epoch  41 |   768/ 1004 batches | lr 0.0003 | ms/batch 82.20 | loss  0.26 | acc     0.92\n",
      "| epoch  41 |   832/ 1004 batches | lr 0.0003 | ms/batch 82.20 | loss  0.26 | acc     0.93\n",
      "| epoch  41 |   896/ 1004 batches | lr 0.0003 | ms/batch 82.27 | loss  0.25 | acc     0.92\n",
      "| epoch  41 |   960/ 1004 batches | lr 0.0003 | ms/batch 82.13 | loss  0.27 | acc     0.92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  41 | time: 106.64s | valid loss  0.29 | valid acc     0.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  42 |    64/ 1004 batches | lr 0.0003 | ms/batch 89.65 | loss  0.27 | acc     0.92\n",
      "| epoch  42 |   128/ 1004 batches | lr 0.0003 | ms/batch 83.13 | loss  0.26 | acc     0.92\n",
      "| epoch  42 |   192/ 1004 batches | lr 0.0003 | ms/batch 83.11 | loss  0.26 | acc     0.92\n",
      "| epoch  42 |   256/ 1004 batches | lr 0.0003 | ms/batch 83.11 | loss  0.26 | acc     0.93\n",
      "| epoch  42 |   320/ 1004 batches | lr 0.0003 | ms/batch 82.99 | loss  0.27 | acc     0.92\n",
      "| epoch  42 |   384/ 1004 batches | lr 0.0003 | ms/batch 83.32 | loss  0.26 | acc     0.93\n",
      "| epoch  42 |   448/ 1004 batches | lr 0.0003 | ms/batch 87.61 | loss  0.26 | acc     0.92\n",
      "| epoch  42 |   512/ 1004 batches | lr 0.0003 | ms/batch 83.22 | loss  0.25 | acc     0.94\n",
      "| epoch  42 |   576/ 1004 batches | lr 0.0003 | ms/batch 83.12 | loss  0.26 | acc     0.92\n",
      "| epoch  42 |   640/ 1004 batches | lr 0.0003 | ms/batch 83.26 | loss  0.26 | acc     0.92\n",
      "| epoch  42 |   704/ 1004 batches | lr 0.0003 | ms/batch 83.36 | loss  0.26 | acc     0.94\n",
      "| epoch  42 |   768/ 1004 batches | lr 0.0003 | ms/batch 83.12 | loss  0.25 | acc     0.92\n",
      "| epoch  42 |   832/ 1004 batches | lr 0.0003 | ms/batch 83.22 | loss  0.26 | acc     0.93\n",
      "| epoch  42 |   896/ 1004 batches | lr 0.0003 | ms/batch 83.25 | loss  0.25 | acc     0.92\n",
      "| epoch  42 |   960/ 1004 batches | lr 0.0003 | ms/batch 83.11 | loss  0.27 | acc     0.91\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  42 | time: 107.94s | valid loss  0.29 | valid acc     0.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  43 |    64/ 1004 batches | lr 0.0002 | ms/batch 84.67 | loss  0.27 | acc     0.92\n",
      "| epoch  43 |   128/ 1004 batches | lr 0.0002 | ms/batch 83.11 | loss  0.26 | acc     0.91\n",
      "| epoch  43 |   192/ 1004 batches | lr 0.0002 | ms/batch 83.65 | loss  0.26 | acc     0.92\n",
      "| epoch  43 |   256/ 1004 batches | lr 0.0002 | ms/batch 83.66 | loss  0.26 | acc     0.92\n",
      "| epoch  43 |   320/ 1004 batches | lr 0.0002 | ms/batch 83.33 | loss  0.27 | acc     0.92\n",
      "| epoch  43 |   384/ 1004 batches | lr 0.0002 | ms/batch 83.37 | loss  0.26 | acc     0.92\n",
      "| epoch  43 |   448/ 1004 batches | lr 0.0002 | ms/batch 83.50 | loss  0.25 | acc     0.92\n",
      "| epoch  43 |   512/ 1004 batches | lr 0.0002 | ms/batch 83.24 | loss  0.25 | acc     0.93\n",
      "| epoch  43 |   576/ 1004 batches | lr 0.0002 | ms/batch 86.50 | loss  0.26 | acc     0.93\n",
      "| epoch  43 |   640/ 1004 batches | lr 0.0002 | ms/batch 83.37 | loss  0.26 | acc     0.92\n",
      "| epoch  43 |   704/ 1004 batches | lr 0.0002 | ms/batch 83.24 | loss  0.26 | acc     0.93\n",
      "| epoch  43 |   768/ 1004 batches | lr 0.0002 | ms/batch 83.12 | loss  0.25 | acc     0.92\n",
      "| epoch  43 |   832/ 1004 batches | lr 0.0002 | ms/batch 83.38 | loss  0.25 | acc     0.93\n",
      "| epoch  43 |   896/ 1004 batches | lr 0.0002 | ms/batch 83.23 | loss  0.25 | acc     0.92\n",
      "| epoch  43 |   960/ 1004 batches | lr 0.0002 | ms/batch 83.25 | loss  0.27 | acc     0.92\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  43 | time: 107.79s | valid loss  0.29 | valid acc     0.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  44 |    64/ 1004 batches | lr 0.0002 | ms/batch 91.62 | loss  0.27 | acc     0.92\n",
      "| epoch  44 |   128/ 1004 batches | lr 0.0002 | ms/batch 83.50 | loss  0.26 | acc     0.91\n",
      "| epoch  44 |   192/ 1004 batches | lr 0.0002 | ms/batch 83.42 | loss  0.26 | acc     0.93\n",
      "| epoch  44 |   256/ 1004 batches | lr 0.0002 | ms/batch 83.58 | loss  0.26 | acc     0.93\n",
      "| epoch  44 |   320/ 1004 batches | lr 0.0002 | ms/batch 83.38 | loss  0.27 | acc     0.92\n",
      "| epoch  44 |   384/ 1004 batches | lr 0.0002 | ms/batch 83.24 | loss  0.26 | acc     0.92\n",
      "| epoch  44 |   448/ 1004 batches | lr 0.0002 | ms/batch 83.38 | loss  0.25 | acc     0.92\n",
      "| epoch  44 |   512/ 1004 batches | lr 0.0002 | ms/batch 83.37 | loss  0.25 | acc     0.94\n",
      "| epoch  44 |   576/ 1004 batches | lr 0.0002 | ms/batch 83.63 | loss  0.26 | acc     0.92\n",
      "| epoch  44 |   640/ 1004 batches | lr 0.0002 | ms/batch 83.36 | loss  0.26 | acc     0.91\n",
      "| epoch  44 |   704/ 1004 batches | lr 0.0002 | ms/batch 83.11 | loss  0.26 | acc     0.93\n",
      "| epoch  44 |   768/ 1004 batches | lr 0.0002 | ms/batch 83.62 | loss  0.25 | acc     0.92\n",
      "| epoch  44 |   832/ 1004 batches | lr 0.0002 | ms/batch 83.40 | loss  0.25 | acc     0.93\n",
      "| epoch  44 |   896/ 1004 batches | lr 0.0002 | ms/batch 83.23 | loss  0.25 | acc     0.92\n",
      "| epoch  44 |   960/ 1004 batches | lr 0.0002 | ms/batch 83.38 | loss  0.27 | acc     0.91\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  44 | time: 108.06s | valid loss  0.29 | valid acc     0.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  45 |    64/ 1004 batches | lr 0.0001 | ms/batch 84.51 | loss  0.27 | acc     0.92\n",
      "| epoch  45 |   128/ 1004 batches | lr 0.0001 | ms/batch 83.37 | loss  0.26 | acc     0.91\n",
      "| epoch  45 |   192/ 1004 batches | lr 0.0001 | ms/batch 87.28 | loss  0.26 | acc     0.92\n",
      "| epoch  45 |   256/ 1004 batches | lr 0.0001 | ms/batch 83.36 | loss  0.26 | acc     0.93\n",
      "| epoch  45 |   320/ 1004 batches | lr 0.0001 | ms/batch 83.49 | loss  0.27 | acc     0.92\n",
      "| epoch  45 |   384/ 1004 batches | lr 0.0001 | ms/batch 83.39 | loss  0.26 | acc     0.92\n",
      "| epoch  45 |   448/ 1004 batches | lr 0.0001 | ms/batch 83.12 | loss  0.26 | acc     0.92\n",
      "| epoch  45 |   512/ 1004 batches | lr 0.0001 | ms/batch 83.39 | loss  0.25 | acc     0.93\n",
      "| epoch  45 |   576/ 1004 batches | lr 0.0001 | ms/batch 83.09 | loss  0.25 | acc     0.93\n",
      "| epoch  45 |   640/ 1004 batches | lr 0.0001 | ms/batch 83.12 | loss  0.26 | acc     0.93\n",
      "| epoch  45 |   704/ 1004 batches | lr 0.0001 | ms/batch 83.24 | loss  0.26 | acc     0.94\n",
      "| epoch  45 |   768/ 1004 batches | lr 0.0001 | ms/batch 83.24 | loss  0.25 | acc     0.93\n",
      "| epoch  45 |   832/ 1004 batches | lr 0.0001 | ms/batch 83.11 | loss  0.25 | acc     0.93\n",
      "| epoch  45 |   896/ 1004 batches | lr 0.0001 | ms/batch 82.98 | loss  0.25 | acc     0.93\n",
      "| epoch  45 |   960/ 1004 batches | lr 0.0001 | ms/batch 83.25 | loss  0.27 | acc     0.91\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  45 | time: 108.00s | valid loss  0.29 | valid acc     0.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  46 |    64/ 1004 batches | lr 0.0001 | ms/batch 85.63 | loss  0.27 | acc     0.92\n",
      "| epoch  46 |   128/ 1004 batches | lr 0.0001 | ms/batch 84.41 | loss  0.26 | acc     0.91\n",
      "| epoch  46 |   192/ 1004 batches | lr 0.0001 | ms/batch 84.16 | loss  0.26 | acc     0.93\n",
      "| epoch  46 |   256/ 1004 batches | lr 0.0001 | ms/batch 84.02 | loss  0.26 | acc     0.93\n",
      "| epoch  46 |   320/ 1004 batches | lr 0.0001 | ms/batch 87.81 | loss  0.27 | acc     0.92\n",
      "| epoch  46 |   384/ 1004 batches | lr 0.0001 | ms/batch 83.36 | loss  0.26 | acc     0.92\n",
      "| epoch  46 |   448/ 1004 batches | lr 0.0001 | ms/batch 83.64 | loss  0.26 | acc     0.92\n",
      "| epoch  46 |   512/ 1004 batches | lr 0.0001 | ms/batch 83.50 | loss  0.25 | acc     0.93\n",
      "| epoch  46 |   576/ 1004 batches | lr 0.0001 | ms/batch 83.63 | loss  0.26 | acc     0.92\n",
      "| epoch  46 |   640/ 1004 batches | lr 0.0001 | ms/batch 83.38 | loss  0.25 | acc     0.92\n",
      "| epoch  46 |   704/ 1004 batches | lr 0.0001 | ms/batch 83.24 | loss  0.26 | acc     0.93\n",
      "| epoch  46 |   768/ 1004 batches | lr 0.0001 | ms/batch 83.26 | loss  0.25 | acc     0.93\n",
      "| epoch  46 |   832/ 1004 batches | lr 0.0001 | ms/batch 83.24 | loss  0.26 | acc     0.92\n",
      "| epoch  46 |   896/ 1004 batches | lr 0.0001 | ms/batch 83.38 | loss  0.25 | acc     0.92\n",
      "| epoch  46 |   960/ 1004 batches | lr 0.0001 | ms/batch 83.48 | loss  0.27 | acc     0.91\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  46 | time: 108.11s | valid loss  0.29 | valid acc     0.95\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  47 |    64/ 1004 batches | lr 0.0001 | ms/batch 85.66 | loss  0.27 | acc     0.92\n",
      "| epoch  47 |   128/ 1004 batches | lr 0.0001 | ms/batch 84.47 | loss  0.26 | acc     0.92\n",
      "| epoch  47 |   192/ 1004 batches | lr 0.0001 | ms/batch 84.30 | loss  0.26 | acc     0.92\n",
      "| epoch  47 |   256/ 1004 batches | lr 0.0001 | ms/batch 84.46 | loss  0.26 | acc     0.93\n",
      "| epoch  47 |   320/ 1004 batches | lr 0.0001 | ms/batch 84.26 | loss  0.27 | acc     0.92\n",
      "| epoch  47 |   384/ 1004 batches | lr 0.0001 | ms/batch 84.31 | loss  0.26 | acc     0.93\n",
      "| epoch  47 |   448/ 1004 batches | lr 0.0001 | ms/batch 89.20 | loss  0.25 | acc     0.93\n",
      "| epoch  47 |   512/ 1004 batches | lr 0.0001 | ms/batch 83.73 | loss  0.25 | acc     0.93\n",
      "| epoch  47 |   576/ 1004 batches | lr 0.0001 | ms/batch 83.58 | loss  0.26 | acc     0.92\n",
      "| epoch  47 |   640/ 1004 batches | lr 0.0001 | ms/batch 83.33 | loss  0.26 | acc     0.92\n",
      "| epoch  47 |   704/ 1004 batches | lr 0.0001 | ms/batch 83.39 | loss  0.26 | acc     0.93\n",
      "| epoch  47 |   768/ 1004 batches | lr 0.0001 | ms/batch 83.37 | loss  0.25 | acc     0.92\n",
      "| epoch  47 |   832/ 1004 batches | lr 0.0001 | ms/batch 83.65 | loss  0.26 | acc     0.92\n",
      "| epoch  47 |   896/ 1004 batches | lr 0.0001 | ms/batch 83.50 | loss  0.25 | acc     0.92\n",
      "| epoch  47 |   960/ 1004 batches | lr 0.0001 | ms/batch 83.53 | loss  0.27 | acc     0.91\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  47 | time: 108.52s | valid loss  0.29 | valid acc     0.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  48 |    64/ 1004 batches | lr 0.0001 | ms/batch 82.28 | loss  0.27 | acc     0.92\n",
      "| epoch  48 |   128/ 1004 batches | lr 0.0001 | ms/batch 81.11 | loss  0.26 | acc     0.92\n",
      "| epoch  48 |   192/ 1004 batches | lr 0.0001 | ms/batch 80.81 | loss  0.26 | acc     0.92\n",
      "| epoch  48 |   256/ 1004 batches | lr 0.0001 | ms/batch 80.90 | loss  0.26 | acc     0.93\n",
      "| epoch  48 |   320/ 1004 batches | lr 0.0001 | ms/batch 81.68 | loss  0.27 | acc     0.92\n",
      "| epoch  48 |   384/ 1004 batches | lr 0.0001 | ms/batch 81.34 | loss  0.26 | acc     0.92\n",
      "| epoch  48 |   448/ 1004 batches | lr 0.0001 | ms/batch 81.94 | loss  0.25 | acc     0.93\n",
      "| epoch  48 |   512/ 1004 batches | lr 0.0001 | ms/batch 82.08 | loss  0.25 | acc     0.93\n",
      "| epoch  48 |   576/ 1004 batches | lr 0.0001 | ms/batch 86.09 | loss  0.26 | acc     0.92\n",
      "| epoch  48 |   640/ 1004 batches | lr 0.0001 | ms/batch 82.18 | loss  0.26 | acc     0.92\n",
      "| epoch  48 |   704/ 1004 batches | lr 0.0001 | ms/batch 82.20 | loss  0.26 | acc     0.93\n",
      "| epoch  48 |   768/ 1004 batches | lr 0.0001 | ms/batch 82.74 | loss  0.25 | acc     0.93\n",
      "| epoch  48 |   832/ 1004 batches | lr 0.0001 | ms/batch 83.92 | loss  0.25 | acc     0.93\n",
      "| epoch  48 |   896/ 1004 batches | lr 0.0001 | ms/batch 82.74 | loss  0.25 | acc     0.92\n",
      "| epoch  48 |   960/ 1004 batches | lr 0.0001 | ms/batch 82.68 | loss  0.27 | acc     0.91\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  48 | time: 106.62s | valid loss  0.29 | valid acc     0.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  49 |    64/ 1004 batches | lr 0.0001 | ms/batch 84.71 | loss  0.27 | acc     0.92\n",
      "| epoch  49 |   128/ 1004 batches | lr 0.0001 | ms/batch 83.55 | loss  0.26 | acc     0.91\n",
      "| epoch  49 |   192/ 1004 batches | lr 0.0001 | ms/batch 84.12 | loss  0.26 | acc     0.92\n",
      "| epoch  49 |   256/ 1004 batches | lr 0.0001 | ms/batch 83.73 | loss  0.26 | acc     0.92\n",
      "| epoch  49 |   320/ 1004 batches | lr 0.0001 | ms/batch 83.57 | loss  0.27 | acc     0.91\n",
      "| epoch  49 |   384/ 1004 batches | lr 0.0001 | ms/batch 83.59 | loss  0.26 | acc     0.92\n",
      "| epoch  49 |   448/ 1004 batches | lr 0.0001 | ms/batch 83.37 | loss  0.25 | acc     0.92\n",
      "| epoch  49 |   512/ 1004 batches | lr 0.0001 | ms/batch 83.23 | loss  0.26 | acc     0.92\n",
      "| epoch  49 |   576/ 1004 batches | lr 0.0001 | ms/batch 83.40 | loss  0.26 | acc     0.92\n",
      "| epoch  49 |   640/ 1004 batches | lr 0.0001 | ms/batch 83.90 | loss  0.26 | acc     0.92\n",
      "| epoch  49 |   704/ 1004 batches | lr 0.0001 | ms/batch 87.78 | loss  0.25 | acc     0.93\n",
      "| epoch  49 |   768/ 1004 batches | lr 0.0001 | ms/batch 83.50 | loss  0.26 | acc     0.93\n",
      "| epoch  49 |   832/ 1004 batches | lr 0.0001 | ms/batch 83.51 | loss  0.26 | acc     0.92\n",
      "| epoch  49 |   896/ 1004 batches | lr 0.0001 | ms/batch 83.48 | loss  0.25 | acc     0.92\n",
      "| epoch  49 |   960/ 1004 batches | lr 0.0001 | ms/batch 83.40 | loss  0.27 | acc     0.91\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  49 | time: 108.08s | valid loss  0.29 | valid acc     0.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  50 |    64/ 1004 batches | lr 0.0001 | ms/batch 83.36 | loss  0.27 | acc     0.92\n",
      "| epoch  50 |   128/ 1004 batches | lr 0.0001 | ms/batch 82.07 | loss  0.26 | acc     0.91\n",
      "| epoch  50 |   192/ 1004 batches | lr 0.0001 | ms/batch 82.07 | loss  0.26 | acc     0.93\n",
      "| epoch  50 |   256/ 1004 batches | lr 0.0001 | ms/batch 82.08 | loss  0.26 | acc     0.92\n",
      "| epoch  50 |   320/ 1004 batches | lr 0.0001 | ms/batch 82.33 | loss  0.27 | acc     0.92\n",
      "| epoch  50 |   384/ 1004 batches | lr 0.0001 | ms/batch 82.07 | loss  0.26 | acc     0.93\n",
      "| epoch  50 |   448/ 1004 batches | lr 0.0001 | ms/batch 82.20 | loss  0.25 | acc     0.92\n",
      "| epoch  50 |   512/ 1004 batches | lr 0.0001 | ms/batch 81.95 | loss  0.25 | acc     0.94\n",
      "| epoch  50 |   576/ 1004 batches | lr 0.0001 | ms/batch 82.06 | loss  0.26 | acc     0.92\n",
      "| epoch  50 |   640/ 1004 batches | lr 0.0001 | ms/batch 82.25 | loss  0.25 | acc     0.91\n",
      "| epoch  50 |   704/ 1004 batches | lr 0.0001 | ms/batch 82.15 | loss  0.26 | acc     0.93\n",
      "| epoch  50 |   768/ 1004 batches | lr 0.0001 | ms/batch 82.08 | loss  0.26 | acc     0.92\n",
      "| epoch  50 |   832/ 1004 batches | lr 0.0001 | ms/batch 86.78 | loss  0.26 | acc     0.92\n",
      "| epoch  50 |   896/ 1004 batches | lr 0.0001 | ms/batch 82.18 | loss  0.25 | acc     0.91\n",
      "| epoch  50 |   960/ 1004 batches | lr 0.0001 | ms/batch 82.07 | loss  0.27 | acc     0.92\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  50 | time: 107.44s | valid loss  0.29 | valid acc     0.95\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float(\"inf\")\n",
    "epochs = params[\"epochs\"] # The number of epochs\n",
    "best_model = None\n",
    "\n",
    "print(\"STARTING:::::::.........\")\n",
    "for epoch in range(1, epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train()\n",
    "    train_loss, train_acc = evaluate(model, train_data, \"train\")\n",
    "    log_metrics({\"train_epoch_loss\":train_loss, \"train_epoch_accuracy\":train_acc})\n",
    "    \n",
    "    val_loss, acc = evaluate(model, val_data, \"other\")\n",
    "    log_metrics({\"validation_loss\":val_loss, \"validation_accuracy\":acc})\n",
    "    print('-' * 89)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n",
    "          'valid acc {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n",
    "                                     val_loss, acc))\n",
    "    print('-' * 89)\n",
    "\n",
    "    _1, _2 = evaluate(model, val_data, \"test\")\n",
    "\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = model\n",
    "\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(best_model.state_dict(), f\"{params['name']}-POSTAGGER-heads{params['heads']}-layers{params['layers']}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss  0.32 | test acc     0.93\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "test_loss, acc = evaluate(model, test_data, \"test\")\n",
    "print('=' * 89)\n",
    "print('| End of training | test loss {:5.2f} | test acc {:8.2f}'.format(\n",
    "    test_loss, acc))\n",
    "print('=' * 89)\n",
    "log_metrics({\"test_loss\":test_loss, \"test_accuracy\":acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 8, 8])\n",
      "torch.Size([8, 1, 240])\n",
      "torch.Size([8, 1, 240])\n",
      "{'training': False, '_parameters': OrderedDict([('weight', Parameter containing:\n",
      "tensor([[-0.0246, -0.0959, -0.0409,  ..., -0.0102, -0.0462, -0.0010],\n",
      "        [-0.0016,  0.0513,  0.1416,  ..., -0.0614,  0.1130, -0.0696],\n",
      "        [ 0.0229,  0.0361, -0.0106,  ..., -0.0882, -0.1163, -0.1099],\n",
      "        ...,\n",
      "        [ 0.0035, -0.0778,  0.0333,  ...,  0.0304,  0.1031,  0.0032],\n",
      "        [ 0.0056, -0.0431, -0.0162,  ..., -0.1074,  0.0186, -0.0449],\n",
      "        [ 0.0466,  0.0509, -0.0273,  ..., -0.0752, -0.0119, -0.0439]],\n",
      "       device='cuda:0', requires_grad=True)), ('bias', Parameter containing:\n",
      "tensor([-0.2343, -0.0939, -0.0874,  ..., -0.1486, -0.0283, -0.0882],\n",
      "       device='cuda:0', requires_grad=True))]), '_buffers': OrderedDict(), '_backward_hooks': OrderedDict(), '_forward_hooks': OrderedDict(), '_forward_pre_hooks': OrderedDict(), '_state_dict_hooks': OrderedDict(), '_load_state_dict_pre_hooks': OrderedDict(), '_modules': OrderedDict(), 'in_features': 240, 'out_features': 1024}\n"
     ]
    }
   ],
   "source": [
    "print(model.transformer.layers[0].attn.shape)\n",
    "print(model.transformer.layers[0].attn_preactivation.shape)\n",
    "print(model.transformer.layers[0].attn_activation.shape)\n",
    "print(model.transformer.layers[0].linear1.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 6\n",
      "Sil : NNP\n",
      "is : VBZ\n",
      "a : LS\n",
      "cute : JJ\n",
      "quirky : JJ\n",
      "girl : NN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frase = \"Sil is a cute quirky girl\".split()\n",
    "\n",
    "\n",
    "def generate_sent(frase, model, TEXT, words=5):\n",
    "    \"\"\"\n",
    "    This function gets a list of a split string and \n",
    "    returns a new string with the next N number of words \n",
    "    predicted by the model\n",
    "    \"\"\"\n",
    "\n",
    "    frasevec = TEXT.numericalize([frase]).to(\"cuda\")\n",
    "    model.eval()\n",
    "    var = model(frasevec, frasevec)\n",
    "    most = torch.argmax(var.squeeze(1), dim=1).cpu().detach().data.numpy()\n",
    "    most = [itotags[x] for x in most]\n",
    "    print(len(frase), len(most))\n",
    "    result = [f\"{frase[x]} : {most[x]}\" for x in range(len(most))]\n",
    "    return result\n",
    "\n",
    "\n",
    "f = generate_sent(frase, model, TEXT)\n",
    "for x in f:\n",
    "    print(x)\n",
    "len(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting layer 1...\n",
      "Plotting layer 2...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x2160 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sent = frase\n",
    "\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "fig, axs = plt.subplots(params[\"layers\"],params[\"heads\"], figsize=(30, 30))\n",
    "\n",
    "for j in range(params[\"layers\"]):\n",
    "    \n",
    "    print(f\"Plotting layer {j+1}...\")\n",
    "    x = model.transformer.layers[j].attn.data\n",
    "    x = F.softmax(x, dim = -1)\n",
    "    \n",
    "    for i in range(x.shape[0]):\n",
    "        \n",
    "        if i != 0:\n",
    "            seaborn.heatmap(x[i,:,:].cpu().numpy(), square=True, cbar=False, \n",
    "                             cbar_kws={\"shrink\": .00001, \"ticks\":None, },\n",
    "                             yticklabels=[\"\"]*len(sent), xticklabels=sent, ax=axs[j,i])\n",
    "            axs[j,i].tick_params(axis='y', which='both', length=0)\n",
    "            \n",
    "        else:\n",
    "            seaborn.heatmap(x[i,:,:].cpu().numpy(), square=True, cbar=False, \n",
    "                             cbar_kws={\"shrink\": .00001, \"ticks\":None, },\n",
    "                             yticklabels=f, xticklabels=sent, ax=axs[j,i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
